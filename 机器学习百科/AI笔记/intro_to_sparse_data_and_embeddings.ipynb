{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_sparse_data_and_embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "mNCLhxsXyOIS",
        "eQS5KQzBybTY",
        "copyright-notice"
      ]
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright-notice"
      },
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "copyright-notice2",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTaAdgy3LS8W",
        "colab_type": "text"
      },
      "source": [
        " # 稀疏数据和嵌入简介\n",
        "\n",
        "**学习目标：**\n",
        "* 将影评字符串数据转换为稀疏特征矢量\n",
        "* 使用稀疏特征矢量实现情感分析线性模型\n",
        "* 通过将数据投射到二维空间的嵌入来实现情感分析 DNN 模型\n",
        "* 将嵌入可视化，以便查看模型学到的词语之间的关系\n",
        "\n",
        "在此练习中，我们将探讨稀疏数据，并使用影评文本数据（来自 [ACL 2011 IMDB 数据集](http://ai.stanford.edu/~amaas/data/sentiment/)）进行嵌入。这些数据已被处理成 `tf.Example` 格式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKGtmwNosU8",
        "colab_type": "text"
      },
      "source": [
        " ## 设置\n",
        "\n",
        "我们导入依赖项并下载训练数据和测试数据。[`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) 中包含一个文件下载和缓存工具，我们可以用它来检索数据集。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWqDqFFL_NZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "9883d675-54f9-441f-8c40-75069c7481bf"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "train_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "test_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/train.tfrecord\n",
            "41631744/41625533 [==============================] - 0s 0us/step\n",
            "41639936/41625533 [==============================] - 0s 0us/step\n",
            "Downloading data from https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/test.tfrecord\n",
            "40689664/40688441 [==============================] - 0s 0us/step\n",
            "40697856/40688441 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W7aZ9qspZVj",
        "colab_type": "text"
      },
      "source": [
        " ## 构建情感分析模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jieA0k_NLS8a",
        "colab_type": "text"
      },
      "source": [
        " 我们根据这些数据训练一个情感分析模型，以预测某条评价总体上是*好评*（标签为 1）还是*差评*（标签为 0）。\n",
        "\n",
        "为此，我们会使用*词汇表*（即我们预计将在数据中看到的每个术语的列表），将字符串值 `terms` 转换为特征矢量。在本练习中，我们创建了侧重于一组有限术语的小型词汇表。其中的大多数术语明确表示是*好评*或*差评*，但有些只是因为有趣而被添加进来。\n",
        "\n",
        "词汇表中的每个术语都与特征矢量中的一个坐标相对应。为了将样本的字符串值 `terms` 转换为这种矢量格式，我们按以下方式处理字符串值：如果该术语没有出现在样本字符串中，则坐标值将为 0；如果出现在样本字符串中，则值为 1。未出现在该词汇表中的样本中的术语将被弃用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HSfklfnLS8b",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*我们当然可以使用更大的词汇表，而且有创建此类词汇表的专用工具。此外，我们可以添加少量的 OOV（未收录词汇）分桶，您可以在其中对词汇表中未包含的术语进行哈希处理，而不仅仅是弃用这些术语。我们还可以使用__特征哈希__法对每个术语进行哈希处理，而不是创建显式词汇表。这在实践中很有效，但却不具备可解读性（这对本练习非常实用）。如需了解处理此类词汇表的工具，请参阅 tf.feature_column 模块。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvoa2HyDtgqe",
        "colab_type": "text"
      },
      "source": [
        " ## 构建输入管道"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O20vMEOurDol",
        "colab_type": "text"
      },
      "source": [
        " 首先，我们来配置输入管道，以将数据导入 TensorFlow 模型中。我们可以使用以下函数来解析训练数据和测试数据（格式为 [TFRecord](https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data)），然后返回一个由特征和相应标签组成的字典。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxxNIEniPq2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels.\n",
        "  \n",
        "  Args:\n",
        "    record: File path to a TFRecord file    \n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "  \n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "\n",
        "  return  {'terms':terms}, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXhTeeYMrp-l",
        "colab_type": "text"
      },
      "source": [
        " 为了确认函数是否能正常运行，我们为训练数据构建一个 `TFRecordDataset`，并使用上述函数将数据映射到特征和标签。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF4YWXR0Omt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c978d48-4144-4d90-8986-da661638257b"
      },
      "source": [
        "# Create the Dataset object.\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map features and labels with the parse function.\n",
        "ds = ds.map(_parse_function)\n",
        "\n",
        "ds"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ({terms: (?,)}, (1,)), types: ({terms: tf.string}, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUoMvK-9tVXP",
        "colab_type": "text"
      },
      "source": [
        " 运行以下单元，以从训练数据集中获取第一个样本。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6QE2DWRUc4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "f1e269eb-3043-4d3c-a462-dedfc3d10bd5"
      },
      "source": [
        "n = ds.make_one_shot_iterator().get_next()\n",
        "sess = tf.Session()\n",
        "sess.run(n)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'terms': array(['but', 'it', 'does', 'have', 'some', 'good', 'action', 'and', 'a',\n",
              "         'plot', 'that', 'is', 'somewhat', 'interesting', '.', 'nevsky',\n",
              "         'acts', 'like', 'a', 'body', 'builder', 'and', 'he', 'isn', \"'\",\n",
              "         't', 'all', 'that', 'attractive', ',', 'in', 'fact', ',', 'imo',\n",
              "         ',', 'he', 'is', 'ugly', '.', '(', 'his', 'acting', 'skills',\n",
              "         'lack', 'everything', '!', ')', 'sascha', 'is', 'played', 'very',\n",
              "         'well', 'by', 'joanna', 'pacula', ',', 'but', 'she', 'needed',\n",
              "         'more', 'lines', 'than', 'she', 'was', 'given', ',', 'her',\n",
              "         'character', 'needed', 'to', 'be', 'developed', '.', 'there',\n",
              "         'are', 'way', 'too', 'many', 'men', 'in', 'this', 'story', ',',\n",
              "         'there', 'is', 'zero', 'romance', ',', 'too', 'much', 'action',\n",
              "         ',', 'and', 'way', 'too', 'dumb', 'of', 'an', 'ending', '.', 'it',\n",
              "         'is', 'very', 'violent', '.', 'i', 'did', 'however', 'love', 'the',\n",
              "         'scenery', ',', 'this', 'movie', 'takes', 'you', 'all', 'over',\n",
              "         'the', 'world', ',', 'and', 'that', 'is', 'a', 'bonus', '.', 'i',\n",
              "         'also', 'liked', 'how', 'it', 'had', 'some', 'stuff', 'about',\n",
              "         'the', 'mafia', 'in', 'it', ',', 'not', 'too', 'much', 'or', 'too',\n",
              "         'little', ',', 'but', 'enough', 'that', 'it', 'got', 'my',\n",
              "         'attention', '.', 'the', 'actors', 'needed', 'to', 'be', 'more',\n",
              "         'handsome', '.', '.', '.', 'the', 'biggest', 'problem', 'i', 'had',\n",
              "         'was', 'that', 'nevsky', 'was', 'just', 'too', 'normal', ',',\n",
              "         'not', 'sexy', 'enough', '.', 'i', 'think', 'for', 'most', 'guys',\n",
              "         ',', 'sascha', 'will', 'be', 'hot', 'enough', ',', 'but', 'for',\n",
              "         'us', 'ladies', 'that', 'are', 'fans', 'of', 'action', ',',\n",
              "         'nevsky', 'just', 'doesn', \"'\", 't', 'cut', 'it', '.', 'overall',\n",
              "         ',', 'this', 'movie', 'was', 'fine', ',', 'i', 'didn', \"'\", 't',\n",
              "         'love', 'it', 'nor', 'did', 'i', 'hate', 'it', ',', 'just',\n",
              "         'found', 'it', 'to', 'be', 'another', 'normal', 'action', 'flick',\n",
              "         '.'], dtype=object)}, array([0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBU39UeFty9S",
        "colab_type": "text"
      },
      "source": [
        " 现在，我们构建一个正式的输入函数，可以将其传递给 TensorFlow Estimator 对象的 `train()` 方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_C5-ueNYIn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input_fn that parses the tf.Examples from the given files,\n",
        "# and split them into features and targets.\n",
        "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
        "  \n",
        "  # Same code as above; create a dataset and map features and labels.\n",
        "  ds = tf.data.TFRecordDataset(input_filenames)\n",
        "  ds = ds.map(_parse_function)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  # Our feature data is variable-length, so we pad and batch\n",
        "  # each field of the dataset structure to whatever size is necessary.     \n",
        "  ds = ds.padded_batch(25, ds.output_shapes)\n",
        "  \n",
        "  ds = ds.repeat(num_epochs)\n",
        "\n",
        "  \n",
        "  # Return the next batch of data.\n",
        "  features, labels = ds.make_one_shot_iterator().get_next()\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y170tVlrLS8c",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 1：使用具有稀疏输入和显式词汇表的线性模型\n",
        "\n",
        "对于我们的第一个模型，我们将使用 50 个信息性术语来构建 [`LinearClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) 模型；始终从简单入手！\n",
        "\n",
        "以下代码将为我们的术语构建特征列。[`categorical_column_with_vocabulary_list`](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list) 函数可使用“字符串-特征矢量”映射来创建特征列。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5gdxuWsvPcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 50 informative terms that compose our model vocabulary. \n",
        "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
        "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
        "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
        "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
        "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
        "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
        "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
        "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
        "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
        "                     \"drama\", \"family\")\n",
        "\n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTiDwyorwd3P",
        "colab_type": "text"
      },
      "source": [
        " 接下来，我们将构建 `LinearClassifier`，在训练集中训练该模型，并在评估集中对其进行评估。阅读上述代码后，运行该模型以了解其效果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYKKpGLqLS8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "06614168-b3be-4e61-a8d3-233fd616bd03"
      },
      "source": [
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "feature_columns = [ terms_feature_column ]\n",
        "\n",
        "\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  optimizer=my_optimizer,\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Training set metrics:\n",
            "loss 11.401773\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.88152\n",
            "auc 0.8709892\n",
            "prediction/mean 0.5369088\n",
            "precision 0.74027544\n",
            "label/mean 0.5\n",
            "average_loss 0.45607093\n",
            "auc_precision_recall 0.8604641\n",
            "accuracy 0.78612\n",
            "---\n",
            "Test set metrics:\n",
            "loss 11.419296\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.87576\n",
            "auc 0.8690995\n",
            "prediction/mean 0.5349597\n",
            "precision 0.7384148\n",
            "label/mean 0.5\n",
            "average_loss 0.45677185\n",
            "auc_precision_recall 0.8574375\n",
            "accuracy 0.78276\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ubn9gULS8g",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 2：使用深度神经网络 (DNN) 模型\n",
        "\n",
        "上述模型是一个线性模型，效果非常好。但是，我们可以使用 DNN 模型实现更好的效果吗？\n",
        "\n",
        "我们将 `LinearClassifier` 切换为 [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier)。运行以下单元，看看您的模型效果如何。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcgOPfEALS8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "1a65e61e-6bef-45f9-87af-6b635669c3a7"
      },
      "source": [
        "##################### Here's what we changed ##################################\n",
        "classifier = tf.estimator.DNNClassifier(                                      #\n",
        "  feature_columns=[tf.feature_column.indicator_column(terms_feature_column)], #\n",
        "  hidden_units=[20,20],                                                       #\n",
        "  optimizer=my_optimizer,                                                     #\n",
        ")                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "try:\n",
        "  classifier.train(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000)\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1)\n",
        "  print(\"Training set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([test_path]),\n",
        "    steps=1)\n",
        "\n",
        "  print(\"Test set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "loss 8.709992\n",
            "accuracy_baseline 0.6\n",
            "global_step 1000\n",
            "recall 0.8666667\n",
            "auc 0.9666665\n",
            "prediction/mean 0.5182824\n",
            "precision 0.9285714\n",
            "label/mean 0.6\n",
            "average_loss 0.3483997\n",
            "auc_precision_recall 0.97499627\n",
            "accuracy 0.88\n",
            "---\n",
            "Test set metrics:\n",
            "loss 13.102522\n",
            "accuracy_baseline 0.52\n",
            "global_step 1000\n",
            "recall 0.9166667\n",
            "auc 0.89102566\n",
            "prediction/mean 0.55779177\n",
            "precision 0.73333335\n",
            "label/mean 0.48\n",
            "average_loss 0.5241009\n",
            "auc_precision_recall 0.91817135\n",
            "accuracy 0.8\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZz68luxLS8j",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 3：在 DNN 模型中使用嵌入\n",
        "\n",
        "在此任务中，我们将使用嵌入列来实现 DNN 模型。嵌入列会将稀疏数据作为输入，并返回一个低维度密集矢量作为输出。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliRzhvJLS8k",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*从计算方面而言，embedding_column 通常是用于在稀疏数据中训练模型最有效的选项。在此练习末尾的[可选部分](#scrollTo=XDMlGgRfKSVz)，我们将更深入地讨论使用 `embedding_column` 与 `indicator_column` 之间的实现差异，以及如何在这两者之间做出权衡。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-as3PtALS8l",
        "colab_type": "text"
      },
      "source": [
        " 在下面的代码中，执行以下操作：\n",
        "\n",
        "* 通过将数据投射到二维空间的 `embedding_column` 来为模型定义特征列（如需详细了解 `embedding_column` 的函数签名，请参阅相关 [TF 文档](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column)）。\n",
        "* 定义符合以下规范的 `DNNClassifier`：\n",
        "  * 具有两个隐藏层，每个包含 20 个单元\n",
        "  * 采用学习速率为 0.1 的 AdaGrad 优化方法\n",
        "  * `gradient_clip_norm 值为 5.0`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlPZ-Q9bLS8m",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*在实践中，我们可能会将数据投射到 2 维以上（比如 50 或 100）的空间中。但就目前而言，2 维是比较容易可视化的维数。*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNCLhxsXyOIS",
        "colab_type": "text"
      },
      "source": [
        " ### 提示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L67xYD7hLS8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's a example code snippet you might use to define the feature columns:\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv1UBsJxyV37",
        "colab_type": "text"
      },
      "source": [
        " ### 完成以下代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PG_yhNGLS8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "f225fe37-2451-4f5f-9de3-c0aeb2c45694"
      },
      "source": [
        "########################## YOUR CODE HERE ######################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[20,20],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "loss 11.360033\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.78448\n",
            "auc 0.8673638\n",
            "prediction/mean 0.48922667\n",
            "precision 0.78422904\n",
            "label/mean 0.5\n",
            "average_loss 0.4544013\n",
            "auc_precision_recall 0.8550669\n",
            "accuracy 0.78432\n",
            "---\n",
            "Test set metrics:\n",
            "loss 11.3915825\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.77568\n",
            "auc 0.8665506\n",
            "prediction/mean 0.48867327\n",
            "precision 0.7827561\n",
            "label/mean 0.5\n",
            "average_loss 0.4556633\n",
            "auc_precision_recall 0.8542593\n",
            "accuracy 0.7802\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQS5KQzBybTY",
        "colab_type": "text"
      },
      "source": [
        " ### 解决方案\n",
        "\n",
        "点击下方即可查看解决方案。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xOdYeQydi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## SOLUTION CODE ########################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[20,20],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "#################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiHnnVtzLS8w",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 4：确信模型中确实存在嵌入\n",
        "\n",
        "上述模型使用了 `embedding_column`，而且似乎很有效，但这并没有让我们了解到内部发生的情形。我们如何检查该模型确实在内部使用了嵌入？\n",
        "\n",
        "首先，我们来看看该模型中的张量："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1jNgLdQLS8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "4b148780-fa5c-4523-f275-09aae5aafe04"
      },
      "source": [
        "classifier.get_variable_names()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dnn/hiddenlayer_0/bias',\n",
              " 'dnn/hiddenlayer_0/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_0/kernel',\n",
              " 'dnn/hiddenlayer_0/kernel/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/bias',\n",
              " 'dnn/hiddenlayer_1/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/kernel',\n",
              " 'dnn/hiddenlayer_1/kernel/t_0/Adagrad',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights/t_0/Adagrad',\n",
              " 'dnn/logits/bias',\n",
              " 'dnn/logits/bias/t_0/Adagrad',\n",
              " 'dnn/logits/kernel',\n",
              " 'dnn/logits/kernel/t_0/Adagrad',\n",
              " 'global_step']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl4-VctMLS8z",
        "colab_type": "text"
      },
      "source": [
        " 好的，我们可以看到这里有一个嵌入层：`'dnn/input_from_feature_columns/input_layer/terms_embedding/...'`。（顺便说一下，有趣的是，该层可以与模型的其他层一起训练，就像所有隐藏层一样。）\n",
        "\n",
        "嵌入层的形状是否正确？请运行以下代码来查明。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNFxyQUiLS80",
        "colab_type": "text"
      },
      "source": [
        " **注意**：*在我们的示例中，嵌入是一个矩阵，可让我们将一个 50 维矢量投射到 2 维空间。*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xMbpcEjLS80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46ecdf04-45ac-4591-c0e5-6aa560a7280c"
      },
      "source": [
        "classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights').shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLCIogjLS82",
        "colab_type": "text"
      },
      "source": [
        " 花些时间来手动检查各个层及其形状，以确保一切都按照您预期的方式互相连接。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkKAaRWDLS83",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 5：检查嵌入\n",
        "\n",
        "现在，我们来看看实际嵌入空间，并了解术语最终所在的位置。请执行以下操作：\n",
        "1. 运行以下代码来查看我们在**任务 3** 中训练的嵌入。一切最终是否如您所预期的那样？\n",
        "\n",
        "2. 重新运行**任务 3** 中的代码来重新训练该模型，然后再次运行下面的嵌入可视化。哪些保持不变？哪些发生了变化？\n",
        "\n",
        "3. 最后，仅使用 10 步来重新训练该模型（这将产生一个糟糕的模型）。再次运行下面的嵌入可视化。您现在看到了什么？为什么？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4NNu7KqLS84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8bf2e6b1-6cdc-4dac-af28-6d1bcedd9393"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "embedding_matrix = classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')\n",
        "\n",
        "for term_index in range(len(informative_terms)):\n",
        "  # Create a one-hot encoding for our term.  It has 0s everywhere, except for\n",
        "  # a single 1 in the coordinate that corresponds to that term.\n",
        "  term_vector = np.zeros(len(informative_terms))\n",
        "  term_vector[term_index] = 1\n",
        "  # We'll now project that one-hot vector into the embedding space.\n",
        "  embedding_xy = np.matmul(term_vector, embedding_matrix)\n",
        "  plt.text(embedding_xy[0],\n",
        "           embedding_xy[1],\n",
        "           informative_terms[term_index])\n",
        "\n",
        "# Do a little setup to make sure the plot displays nicely.\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
        "plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.show() "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzs3XlcVdX6+PHPAlEUFEjJ1FDQRJkP\ng4oCzhkOiabmmJJl4dCgN5sTM7u/TLKuDZKVkKnlGKFWNwe8YupXQBFzFuU6pqCCoqAMz+8P5FxQ\nQFAEh/V+vc7rnr3P2nuvzbWzztrrWc9SIoKmaZqmVYRJdVdA0zRNu/foxkPTNE2rMN14aJqmaRWm\nGw9N0zStwnTjoWmaplWYbjw0TdO0CtONh6ZpmlZhuvHQNE3TKkw3HpqmaVqF1ajuCpSlQYMGYm9v\nX93V0DRNu2ckJCSkiYjtnb7OXd142NvbEx8fX93V0DRNu2copf5bFdfRj600TdO0CtONh6ZpmlZh\nuvHQNE3TKkw3HpqmaVqF6cZD0zRNqzDdeGiapmkVphsPTdM0rcJ046FpmqZVmG48NE3TtArTjYem\naZpWYbrx0DStSgUHB7Ns2bLqroZ2m3TjoWlalcnLy6vuKmiV5LYbD6WUnVIqRim1Rym1Wyn1Sgll\nlFJqtlLqkFIqSSnldbvX1TTtzkpJSaF169YMHz4cJycnBg4cyOXLl1m3bh2enp64ubkxevRorly5\nAlDqfnt7e9544w28vLxYunSp8fzr16+nX79+xu01a9bQv3//qr1J7ZZVRs8jF/iHiDgDvsB4pZTz\ndWV6Ai2vvV4A5lTCdTVNu8P279/PuHHj2Lt3L/Xq1WPWrFkEBwezePFidu3aRW5uLnPmzCE7O7vE\n/YXq16/P9u3bGTJkiHFfly5d2LdvH6mpqQBEREQwevToKr9H7dbcduMhIqdEZPu19xeBvUCT64oF\nAfOlwFbAWinV6HavrWnanWVnZ4efnx8AI0aMYN26dTg4OODo6AjAqFGj2LhxI/v37y9xf6HBgwff\ncG6lFM888wwLFiwgPT2dLVu20LNnzyq4K60yVOp6Hkope8AT+L/rPmoCHCuyffzavlOVeX1N0yqX\nUqrYtrW1NWfPnq3weSwsLErc/+yzz/Lkk09ibm7OoEGDqFHjrl5iSCui0gbMlVKWwHLgVRG5cBvn\neUEpFa+Uii/szmqaVj2OHj3Kli1bAFi0aBE+Pj6kpKRw6NAhAH744Qc6depEq1atStx/M40bN6Zx\n48ZMnz6dZ5999s7diFbpKqXxUEqZUdBwLBSRFSUUOQHYFdl+9Nq+G4jIXBHxEREfW9s7vpKipmll\naNWqFV9++SVOTk6cP3+eiRMnEhERwaBBg3Bzc8PExISQkBDMzc1L3F8ew4cPx87ODicnpzt8N1pl\nUiJyeyco6Nd+D5wTkVdLKdMbmAD0AtoBs0Wk7c3O7ePjI3oZWk2rHikpKfTp04e//vrrjl5nwoQJ\neHp68txzz93R65RXVFQUjo6OODtfH/dzb1BKJYiIz52+TmX0PPyAZ4CuSqnEa69eSqkQpVThT49f\ngcPAIeAbYFwlXFfTtHuct7c3SUlJjBgxosqvXdqck6ioKPbs2VPFtbn33HbP407SPQ9N00oyc+ZM\natWqxcsvv8zEiRPZuXMn69evZ/369Xz33Xf06dOHf/7zn4gIvXv3ZsaMGQBYWlry4osvsnbtWr78\n8ktWrVpFdHQ0NWrUoEePHjz11FP06dMHKysrrKysWL58OS1atKjmu62Ye6nnoWmaVqUCAgKIjY0F\nID4+nszMTHJycoiNjcXR0ZE33niD9evXk5iYSFxcHFFRUQBcunSJdu3asXPnTpycnPj555/ZvXs3\nSUlJvPvuu3To0IG+ffsyc+ZMEhMT77mGoyrpxkPTtHuOt7c3CQkJXLhwgVq1atG+fXvi4+OJjY3F\n2tqazp07Y2trS40aNRg+fLhxzompqSkDBgwAwMrKCnNzc5577jlWrFhBnTp1qvOW7jm68dA07Z5j\nZmaGg4MDkZGRdOjQgYCAAGJiYjh06BD29valHmdubo6pqSkANWrUYNu2bQwcOJBVq1YRGBhYRbW/\nP+jGQ9O0e1JAQABhYWF07NiRgIAAwsPD8fT0pG3btvznP/8hLS2NvLw8fvzxxxLnnGRmZpKRkUGv\nXr349NNP2blzJwB169bl4sWLVX079xzdeGiadk8KCAjg1KlTtG/fnoYNG2Jubk5AQACNGjXio48+\nokuXLnh4eODt7U1QUNANx1+8eJE+ffrg7u6Ov78/s2bNAmDIkCHMnDkTT09PkpOTq/q27hk62krT\nNO0+oqOtNE3TtLuWbjw0TdO0CtONh6ZpmlZhuvHQNE2rBA9aWhPdeGiaplUC3XhomqY9IGbOnMns\n2bMBmDhxIl27dgUK1lcfPnw4Y8eOxcfHBxcXF0JDQ43Hvfnmmzg7O+Pu7s5rr73G5s2biY6OZvLk\nyRgMBpKTk0lOTiYwMBBvb28CAgLYt29ftdzjHSMid+3L29tbNO1BFRoaKjNnziz185iYGOndu7eI\niERERMj48eOrqmr3jS1btsjAgQNFRMTf31/atGkjV69elalTp0p4eLicPXtWRERyc3OlU6dOsnPn\nTklLSxNHR0fJz88XEZHz58+LiMioUaNk6dKlxnN37dpVDhw4ICIiW7dulS5dulTJPQHxUgXfz3rN\nR03THljX58jy8vIy5siaPXs2S5YsYe7cueTm5nLq1Cn27NmDs7OzMSdWnz596NOnzw3nzczMZPPm\nzQwaNMi478qVK1V5a3ecfmylaXeRDz/8EEdHR/z9/dm/fz8AnTt3pnCybFpaWpm5m7SKKStHVu3a\ntQkLC2PdunUkJSXRu3dvsrOzy5UTKz8/H2traxITE42vvXv3VsMd3jm68dC0u0RCQgI//fQTiYmJ\n/Prrr8TFxVV3lR4IpeXIunDhAhYWFlhZWXH69Gl+++03oHw5serVq4eDgwNLly4FCoYHCsvdL3Tj\noWl3idjYWPr370+dOnWoV68effv2re4qPRBKy5Hl4eGBp6cnrVu3ZtiwYfj5+QHlz4m1cOFCvvvu\nOzw8PHBxceGXX36pztusdJUy5qGUmgf0Ac6IiGsJn3cGfgGOXNu1QkSmVca1Ne1uVVlrgNeoUYP8\n/Hyio6PZsmULAMHBwTg4ONxQdsOGDYSFhbFq1arbuuaDpFu3buTk5Bi3Dxw4YHwfGRlZ4jHbtm27\nYZ+fn98Nobq///575VTyLlRZPY9I4GbJ8GNFxHDtpRsOTbtOx44diYqKIisri/Pnz7Ny5UoA7O3t\n2bZtG3379qVhw4bVXEtNK1ApjYeIbATOVca5NO1+kpeXx5gxY3BxcaFHjx5kZWWRmJiIr68v7u7u\n9O/fn/PnzwMwadIkLC0tsbGxwcvLi7y8PJYvX862bdt4//33adasGQsWLDCeOyEhgU2bNuHo6Ehi\nYuIN17506RKjR4+mbdu2eHp63nePTbTqVZVjHu2VUjuVUr8ppVxKK6SUekEpFa+Uik9NTa3C6mla\n5Tt48CDjx49n9+7dWFtbs3z5ckaOHMmMGTNISkrCzc2N999/31jeYDCQnZ3NkSNH6NixI/Xr12fH\njh2kpqby/vvv4+vrS0pKCgBXr17l3LlzrF69mmXLlhEWFlbs2h9++CFdu3Zl27ZtxMTEMHnyZC5d\nulSVt6/dx6qq8dgONBMRD+BzIKq0giIyV0R8RMTH1ta2iqqnaXeGg4MDBoMBKJhTkJycTHp6unFl\nu1GjRhnX1wYYPHhwseMHDRpkXDb1ek8//TQmJia0bNmS5s2b3zCD+Y8//uCjjz7CYDDQuXNnsrOz\nOXr0aGXenvYAq5JJgiJyocj7X5VSXymlGohIWlVcX9OqS61atYzvTU1NSU9PL7O8hYVFmdtFKaXK\n3BYRli9fTqtWrcpbXU0rtyrpeSilHlHX/mUrpdpeu+7Zqri2pt1NrKyssLGxITY2FoAffvjhhvW1\nU1JScHW9IWjxBkuXLiU/P5/k5GQOHz5sbCQOHDjA2rVreeKJJ/j888+Ra6uF7tixo5LvRisUGxuL\ni4sLBoOBrKysUssVnfB5r6usUN0fgc5AA6XUcSAUMAMQkXBgIDBWKZULZAFDpPBftKY9YL7//ntC\nQkK4fPkyzZs3JyIi4pbO07RpU9q2bcuFCxcIDw/H3NycvLw8HB0d6d69O35+frz66qu4u7uTn5+P\ng4ODDuG9QxYuXMhbb73FiBEjqrsqVacqEmjd6ksnRtQeREeOHJFWrVrJsGHDpHXr1jJgwAC5dOmS\nrF27VgwGg7i6usqzzz4r2dnZIiLSrFkzef3118XT01N+/PHHYgn6mjVrJlOmTBFPT09xdXWVvXv3\niojImTNnpHv37uLs7CzPPfecNG3aVFJTU6vtnu8mQUFB4uXlJc7OzvL111/LkiVLZOLEiSIi8tln\nn4mDg4OIiCQnJ0uHDh3km2++ERsbG7G3t5dhw4YVS1gpIjJ+/HiJiIgQEZFOnTpJXFzcHa0/VZQY\nUc8w17S70P79+xk3bhx79+6lXr16zJo1i+DgYBYvXsyuXbvIzc1lzpw5xvL169dn+/btDBky5IZz\nNWjQgO3btzN27FhjRNb7779P165d2b17NwMHDizXQPrs2bNxcnJi+PDhJX4eHx/Pyy+/DBRMrpsw\nYcKt3Hq1mzdvHgkJCcTHxzN79mw6dOhgfMwYGxtL/fr1OXHiBLGxsXTs2JHnn3+evn37MnPmTBYu\nXFjNta86uvHQtLuQnZ2dMR3GiBEjWLduHQ4ODjg6OgI3j9Iq6qmnngIKor0Kw3w3bdpkbGgCAwOx\nsbG5aZ2++uor1qxZU+oXpI+Pj3FtjHvZ7Nmz8fDwwNfXl2PHjnHs2DEyMzO5ePEix44dY9iwYWzc\nuJHY2FgCAgKqu7rVRjcemnYXUkoV+yVvbW1dZvmyorIKI75MTU3Jzc29pfqEhIRw+PBhevbsyYwZ\nM2jfvj2enp506NDBmP13w4YNJaYnX7p0Ka6urnh4eNCxY8dbun5V2bBhA2vXrmXLli3s3LkTT09P\nsrOz6dChAxEREbRq1YqAgABiY2PZsmWLsYEvqjCdTKHs7OyqvIUqoxsPTbsLHT16lJycHGbPns2i\nRYvw8fEhJSWFQ4cOASVHaVWEn58fS5YsAQrmgxTOci9NeHg4jRs3JiYmhrFjxxIbG8uOHTuYNm0a\nb7/9dpnHTps2jX//+9/s3LmT6OjoW65zVcjIyMDGxoY6deqwb98+tm7dChTPvOvp6UlMTAy1atXC\nysrqhnM0a9aMPXv2cOXKFdLT01m3bl1V30aV0I2HppVDv3798Pb2xsXFhblz5wJgaWnJO++8Y3zE\ncfr0aaAgaeHLL79Mhw4daN68OcuWLQMKglMmT56Mq6srbm5uLF68GICRI0cSFfW/ebOvvvoqjRs3\nZsqUKVhaWnL+/HkuX76Ms7MzBoOBmjVrsm/fPkJCQgBIT0/H19cXf39/hg4dWq5EjKGhofzxxx+4\nurqydOlSHnnkEerWrVuuv0VGRgaDBg3C1dWViRMnsnv37jLL+/n5ERwczDfffENeXl65rlFdAgMD\nyc3NxcnJiTfffBNfX1+goPE4duwYHTt2xNTUFDs7O/z9/Us8h52dHU8//TSurq48/fTTeHp6VuUt\nVJ2qGJW/1ZeOttLuFoXLkV6+fFlcXFwkLS1NAImOjhYRkcmTJ8sHH3wgIgXLkQ4cOFDy8vJk9+7d\n0qJFCxERWbZsmXTv3l1yc3Pl77//Fjs7Ozl58qRs2LBBgoKCREQkPT1d7O3tJScnp1jUTmhoqLRv\n316ys7MlNTVVHnroIbl69aps27ZNPDw8JCsrSy5cuCCPPfZYmUvXFsrOzpacnBwREdm8ebN4eHjc\n9JhmzZpJamqqjBo1Sj799FMRKYgMa9asmYiUvSzu1q1b5b333pNmzZpJWlraTa+l3Tp0tJWm3T2u\nH0Q9ePAgNWvWND7jLzoYDQU9FRMTE5ydnY09kk2bNjF06FBMTU1p2LAhnTp1Ii4ujk6dOnHw4EFS\nU1P58ccfGTBgADVq3DgFq3fv3tSqVYsGDRrw8MMPc/r0af7880+CgoIwNzenbt26PPnkkzccl5KS\nQuvWrRk+fDhOTk4MHDiQ/fv307p1a2rXrk23bt2ws7MzLpO6bt06PD09cXNzY/To0cb9x48f5/33\n3ycqKor//ve/QOkpy4tKTk6mXbt2TJs2DVtbW44dO1ahv712d9KNh6bdRGmDqGZmZsaUINcPRhdN\nS1LwY7BsI0eOZMGCBURERDB69OgSy1yf6qQig9/Xh/5GR0dz5coVdu7cyeXLl7GxsWHOnDlkZ2eX\nGRL80EMP8dtvv7F69Wo8PT3LVYfJkyfj5uaGq6srHTp0wMPDo9z11u5euvHQtJsobRC1ogICAli8\neDF5eXmkpqayceNG2rZtCxSMk3z22WcAODs7l/ucfn5+rFy5kuzsbDIzM0udQV7e0N/9+/eXGhL8\n6KOPMnr0aNq3b8+BAwfYsWMH06dPN/a4OnfubLx+cHAwX3zxBQArVqxg165d/PXXX/zrX/+6IQeX\ndm+qksSImnYvCwwMJDw8HCcnJ1q1amUcRK2o/v37s2XLFjw8PFBK8fHHH/PII48A0LBhQ5ycnOjX\nr1+FztmmTRv69u2Lu7s7DRs2xM3NrcQIoOu/sK2trTl7tuLp5coKCdYeMFUxsHKrLz1grj0oLl26\nJM2bN5f09PQKH3vx4kXjOby9vSUhIaHY50eOHBFANm/eLCIizz33nEyfPl3s7Ozk4MGDIlIwyP/Z\nZ59JVlZWiftF/jdgrt3d0APmmvZgWLt2LU5OTrz00ksl9hpu5oUXXsBgMODl5cWAAQPw8vK6oUyr\nVq348ssvcXJy4vz580ycOJGIiAgGDRqEm5sbJiYmhISEYG5uXuJ+TbueknIM5lUXHx8fuV/SF2ta\ndUlJSaFPnz7lmv+h3fuUUgki4nOnr6N7HpqmaVqF6cZD0+5z9vb2utehVTrdeGiapmkVVimNh1Jq\nnlLqjFKqxJ83qsBspdQhpVSSUurGET1N0zTtnlFZPY9IILCMz3sCLa+9XgDmlFFW0zRNu8tVSuMh\nIhuBc2UUCQLmXwtD3gpYK6UaVca1NU3TtKpXVWMeTYCi2dCOX9unaZqm3YPuugFzpdQLSql4pVR8\nampqdVdH0zRNK0FVNR4nALsi249e23cDEZkrIj4i4mNra1slldM0TdMqpqoaj2hg5LWoK18gQ0RO\nVdG1NU3TtEpWKVl1lVI/Ap2BBkqp40AoYAYgIuHAr0Av4BBwGXi2Mq6raZqmVY9KaTxEZOhNPhdg\nfGVcS9M0Tat+d92AuaZpmnb3042HpmmaVmG68dA0TdMqTDcemqZpWoXpxkPTNE2rMN14aJr2wJk6\ndSphYWFMmTKFtWvXVmtdevXqRXp6epllIiMjOXny5B2vi1IqWCnVuDxlKyVUV9M07V40bdq06q4C\nv/76603LREZG4urqSuPG5fpevx3BwF/ATVsq3fPQNO2B8OGHH+Lo6Ii/vz/79+8HIDg4mGXLlgHw\n5ptv4uzsjLu7O6+99hoAK1eupF27dnh6etK9e3dOnz4NFPRcnnnmGdq3b0/Lli355ptvANiwYQMd\nO3akd+/etGrVipCQEPLz8wH48ccfcXNzw9XVlTfeeMNYL3t7e9LS0khJScHJyYkxY8bg4uJCjx49\nyMrKYtmyZcTHxzN8+HAMBgNZWVnY29vz1ltvYTAY8PHxYfv27TzxxBO0aNECwJjXSSk1WSkVd20d\npfev7bNXSu1VSn2jlNqtlPpDKVVbKTUQ8AEWKqUSlVK1y/yDishd+/L29hZN0+4Nubm51V2FUsXH\nx4urq6tcunRJMjIypEWLFjJt2jRp166dLF26VNLS0sTR0VHy8/NFROT8+fMiInLu3Dnjvm+++UYm\nTZokIiKhoaHi7u4uly9fluHDh8sjjzwiJ06cEHNzc6lVq5YkJydLbm6udO/eXZYuXSqDBg2S+vXr\ny5kzZyQnJ0e6dOkiP//8s4iINGvWTFJTU+XIkSNiamoqO3bsEBGRQYMGyQ8//CAiIp06dZK4uDjj\n/TRr1ky++uorERF59dVXxc3NTS5cuCBnzpwRIEdEAHoAcwFFQUdhFdARsAdyAcO1ckuAEdfebwB8\npBzfz7rnoWkaM2fOZPbs2QBMnDiRrl27ArB+/XqGDx9e6q9mS0tL/vGPf+Dh4cGWLVtK/PWemprK\ngAEDaNOmDW3atOHPP/+s8vuLjY2lf//+1KlTh3r16tG3b1+ysrKMPRArKyvMzc157rnnWLFiBXXq\n1AHg+PHjPPHEE7i5uTFz5sxia8EHBQVRs2ZNFixYwOOPP862bdsAaNu2Lc2bN8fU1JShQ4eyadMm\n0tLScHFxwdbWlho1ajB8+HA2btx4Qz0dHBwwGAwAeHt7k5KSUuo99e3bFwA3NzfatWtH3bp1uZZM\nNl8pZU1B49ED2AFsB1pTsCAfwBERSbz2PoGCBqVC9JiHpmkEBATwySef8PLLLxMfH8+VK1fIyckh\nNjYWR0dH3njjDRISErCxsaFHjx5ERUXRr18/Ll26RLt27fjkk084e/Yszz33HPv27UMpZRwEfuWV\nV5g4cSL+/v4cPXqUJ554gr1791bzHReMNVy4cIHXXnuN//u//2PIkCHMmzePqKgorKysOHLkCGPG\njOHYsWN069aNjRs3kpGRgaWlJW5ubhw+fJgePXrw7rvvYmFhgVIKgMOHD+Pi4sIjjzxC3759jfsL\nJSQkMGPGDDIyMti9ezd5eXnGz2rVqmV8b2pqSlZWVqn1LyxrYmJS7LhralDQ4/h/IvJ10Q+UUvbA\nlSK78oCyH1GVQPc8NE3D29ubhIQELly4QK1atWjfvj3x8fHExsZibW1N586dS/zVbGpqyoABA4DS\nf72vXbuWCRMmYDAY6Nu3LxcuXCAzM7NK769jx45ERUWRlZXFxYsXWblyJb169aJevXqEhYXh7+/P\nnj17OHDgAMnJyZw4cYKNGzdy8eJFTp48ybhx4+jSpQvm5uZcunSJRx99lEaNGuHj40NOTg4JCQm0\nadOG7Oxszpw5w6pVq4wNsr+/Pw0aNGDPnj2cOnWKCRMm8MgjjzB37lxGjx5900grgLp163Lx4sWK\n3va/gdFKKUsApVQTpdTDNznmIlC3PCfXPQ9N0zAzM8PBwYHIyEg6dOiAu7s7MTExHDp0CHt7exIS\nEko8ztzcHFNTUwBq1KjBtm3bWLduHcuWLeOLL75g/fr15Ofns3XrVszNzavylorx8vJi8ODBeHh4\n8PDDD9OmTZtin//2228sWbLEOHhubW3NwYMHeeWVVxg/fjzjx4+na9euHDlyBFNTU5ycnKhduzZd\nunRh586dTJw4kcaNG6OUol27dkyYMIG9e/dy+fJl+vfvz8qVKxk+fDgdO3bk8OHD1K9fn9DQUPLy\n8sjNzb1p/YODgwkJCaF27dps2bKlXPcsIn8opZyALdd6P5nACAp6GqWJBMKVUllAexEpvetTnoGR\n6nrpAXNNqzqhoaFiZ2cna9askb///lvs7OykX79+cvLkSWnatKmkpqZKbm6udOvWTaKiokRExMLC\nwnj8xYsX5fTp0yIikp6eLg899JCIiAwdOlQ+/vhjY7nCAeHqduTIEXFxcRERkUmTJkl4eHiZZQpZ\nWFhIaGiozJw5U0SKD2YrpaRXr14iIpKcnCwGg0FEREaNGiVLly6VpKQk8fX1vWP3JCICxEsVfD/r\nx1aapgEF4x6nTp2iffv2NGzYEHNzcwICAmjUqBEfffQRXbp0wcPDA29vb4KCgm44/uLFi/Tp0wd3\nd3f8/f2ZNWsWALNnzyY+Ph53d3ecnZ0JDw+v6lsrUdFHQU888QTz5s0zPk47ceIEZ86cqfA5RYRT\npwrWuVu0aBH+/v7FPm/VqhWpqanG3kNOTg67d+++nduoNvqxlaZpAHTr1o2cnBzj9oEDB4zvhw4d\nytChNy7bU3TsolGjRsaIo6IaNGjA4sWLK7m2t69+/fr4+fnh6upKz549GTZsGO3btwcKosgWLFhg\nfCR3valTp5a438LCgs6dO+Pq6srDDz98w33XrFmTZcuW8fLLL5ORkUFubi6vvvoqLi4ulXpvVUEV\n9HJu8yRKBQL/AkyBb0Xko+s+DwZm8r91y78QkW9vdl4fHx+Jj4+/7frdj9LT01m0aBHjxo3j5MmT\nvPzyy8bntZp2t5k6dSqWlpZcuHCBjh070r1792qrS69evVi0aBHW1tallomMjKRHjx7GGd3PP/88\nkyZNwtnZuaqqecuUUgki4nPHr3O7jYdSyhQ4ADwOHAfigKEisqdImWAKJp5MqMi5deNRupSUFPr0\n6VMs7lzT7laFjUfh3I+7XefOnQkLC8PH545/B1e6qmo8KmPMoy1wSEQOi8hV4CfgxgeiWqV68803\nSU5OxmAwMGjQIFxdXYGCX0z9+vXj8ccfx97eni+++IJZs2bh6emJr68v586dAyA5OZnAwEC8vb0J\nCAhg37591Xk72n3ofkoH0rlzZwp/yFpaWvLOO+/g4eGBr6+vsY7Jycn4+vri5ubGu+++i6WlZRX8\nlavR7Y64AwMpeFRVuP0MBY+lipYJBk4BScAywK4859bRVqUrGgVS9H1ERIS0aNHCmKqgXr16MmfO\nHBEpSGPw6aefiohI165d5cCBAyIisnXrVunSpUs13IV2vyopHcjMmTONUUe3kw4kNTVVHn30UTlx\n4oTExMSUmA7kxIkTYmdnV2npQIpuAxIdHS0iIpMnT5YPPvhARER69+4tixYtEhGROXPmFItEq0pU\nUbRVVQ2YrwR+FJErSqkXge+BriUVVEq9ALwA0LRp0yqq3v2lS5cu1K1bl7p162JlZcWTTz4JFKQx\nSEpKIjMzk82bNzNo0CDjMVeuXCntdJpWYUXTgcD/UmkUKjqhsE+fPvTp0wcoSAcyePBgTp06xdWr\nV3FwcDAeExQURO3atY3zK7Zt24a1tbUxHQhgTAdiZmZmnNgIGCc29uvXr1g9KpIOpFDNmjWN9fX2\n9mbNmjUAbNmyhaioKACGDRs5CXauAAAgAElEQVR2zzyiu1WV8djqBGBXZPtR/jcwDoCInBWRwm+n\nbwHv0k4mInNFxEdEfAr/j9cqpmiqgqKpC0xMTMjNzSU/Px9ra2sSExONr7shXYT24CicUDhw4EBW\nrVpFYGAgAC+99BITJkxg165dfP3112RnZxuPuT7NR+F2afvL4/p0IOWZsGdmZma8RnmPuR9VRuMR\nB7RUSjkopWoCQ4DoogWUUo2KbPYF9DfVbbrFdAUA1KtXDwcHB5YuXQoUPLrcuXNnZVZPe8CVlA6k\nqMzMTDIyMujVqxeffvqp8d9fRkYGTZo0AeD7778vdswvv/xCdnY2Z8+eZcOGDcZZ4tu2bePIkSPk\n5+ezePFi/P39adu2Lf/5z39IS0sjLy+PH3/8kU6dOpW7/rfy35evry/Lly8H4KeffqrQsfei235s\nJSK5SqkJFORRMQXmichupdQ0Cp69RQMvK6X6UpAG+BwFYyDabSgao+7k5FTh4xcuXMjYsWOZPn06\nOTk5DBkyBA8PjztQU+1BdLN0IBcvXiQoKIjs7GxExDihcOrUqQwaNAgbGxtjOpBC7u7udOnShbS0\nNN577z0aN27MgQMHaNOmDRMmTODQoUN06dKF/v37Y2JiYpzYKCL07t27xImNpbmVdCCfffYZI0aM\n4MMPPyQwMBArK6tyX+9eVCnzPO4UHar7YLs+1l57cJUW6rthwwbCwsJYtWpVNdXsfy5fvkzt2rVR\nSvHTTz/x448/8ssvv1R5PaoqVFfPMNfuWlW49Kam3baEhAQmTJiAiGBtbc28efOqu0p3lO55aFUm\nJSWFnj174u/vz+bNm2nSpAm//PIL+/fvJyQkhMuXL9OiRQvmzZvHunXrCA4OpkmTJsZHB7VrV3jJ\nAU174NxLkwQ1rdwOHjzI+PHj2b17N9bW1ixfvpyRI0cyY8YMkpKScHNz4/3332fgwIH4+PiwcOFC\nEhMTdcOhaXcZ3XhoFZKSkmKczX4rro+rT05OJj093RgJM2rUqBKX59Q07e6iGw+tyuTm5t4QV1+e\nVdQ0Tbv76AFzrcLy8vIYM2ZMsXGLkydPMn78eFJTU6lTpw7ffPMNrVu3Jjg4GHNzc3bs2IGbm9sN\n57KyssLGxobY2FgCAgL44YcfjL2Q25nLomnanaV7HlqFlTRu8cILL/D555+TkJBAWFgY48aNM5Y/\nfvw4ixYtIjY2tsTzff/990yePBl3d3cSExOZMmUK8L9Y+8LkdLcqPDyc+fPn3/LxmqbdSPc8tAor\nKR9QWbmyBg0ahKmpKWZmZsVSyBeN2d+6desN1xkwYAADBgy47fqGhITc9jm0u9PtLE2glzW4Pbrn\noZXogw8+oFWrVvj7+zN06FDCwsJITEykf//+HDt2jP79+3P+/HlMTU3Zt28feXl55Ofn4+DgQExM\nDHv37iUhIYHo6GhCQ0P58ssvy3XdlJQU4+MuR0dHhg8fztq1a/Hz86Nly5Zs27aNc+fO0a9fP9zd\n3fH19SUpKYn8/Hzs7e2LjaG0bNmS06dPM3XqVMLCwgCdil7TKotuPDSj2bNn4+TkRGBgIMuXL2fn\nzp389ttvxnUMRo4cyRtvvMFjjz1mDKkFWLNmDS1btuS9997Dzc2NwMBAvv76a5599lkAxo4dW6F6\nHDp0iH/84x/s27ePffv2sWjRIjZt2kRYWBj//Oc/CQ0NxdPTk6SkJP75z38ycuRITExMCAoK4uef\nfwbg//7v/2jWrBkNGzYsdu6yHq9p96bc3FyGDx+Ok5MTAwcO5PLly0ybNo02bdrg6urKCy+8ULg0\nBAkJCXh4eODh4VHuHzRayXTjoRl99dVXrFmzhsDAQIKCgjA3N6du3bo8+eSTXLp0ifT0dHx9fYH/\nhdRmZWWRnZ3NqlWr+O6771iyZAk7d+4kJSWF9PR0atasCcAzzzxT7no4ODjg5uaGiYkJLi4udOvW\nDaUUbm5upKSksGnTJuP5unbtytmzZ7lw4QKDBw82rhn9008/MXjw4GLnLZqK3mAw8OKLL3Lq1KnK\n+NNp1Wj//v2MGzeOvXv3Uq9ePb766ismTJhAXFwcf/31F1lZWcb0Jc8++yyff/65TgRaCXTjoQEF\n4wKHDx+mZ8+erFu3ju+++w5PT086dOhgXH3w0qVLvPrqqzRq1IhOnTqRmpqKiYkJWVlZDB06lEWL\nFrF69WosLCxo3bo1AK1bt6Zbt278/PPPxb6ov/nmGyZOnGjc7tWrFydPngRunlK+NO3bt+fQoUOk\npqYSFRXFU089VexznYr+/mRnZ4efnx8AI0aMYNOmTcTExNCuXTvc3NxYv349u3fvJj09nfT0dDp2\n7AhU7AeNdiPdeGhAQURS48aNiYmJYdKkSdja2rJlyxbeeustli1bhoWFBXXq1CE+Pp4VK1YwdOhQ\nzpw5Q/369XFycqJp06bMnz+fH374gYYNG2JhYYG1tTUZGRkApKenc/HiRXJycgCIiIhg9OjRxuv/\n+uuv5c5hFRAQwMKFC4GCxHgiQrt27XjooYdo3LgxkyZNokaNGkRERBQ7Tqeivz+VtJ7HuHHjWLZs\nGbt27WLMmDHF1gXRKoduPO6gogO1JUlNTTWu1xwbG0uvXr1uOmluypQprF27FihIAX358uWb1qPo\n+svl8dhjj5GdnY2VlRVDhgxBKYWVlRVjxozh6tWr+Pn5cfDgQWxtbXnyySf5/vvviY+PZ/r06SQm\nJhojsSIiIjh48CDDhg3DzMwMCwsLVq1axb59+8jJySlx3kd5TJ06lYSEBNzd3XnzzTcxMzNjzZo1\nnD9/nlmzZrFgwQJcXFxKPHbhwoV89913eHh44OLiUi1ZT7XKdfToUWPa9EWLFuHv7w9AgwYNyMzM\nNK6Zbm1tjbW1NZs2bQIw/gDRbo1uPKrRunXrcHNzY8eOHQQEBPDrr79ibW1d5jHTpk2je/fuQPkb\nj4p67733GD16NFeuXCE+Pp6rV6/i7e1N06ZNefrpp0lKSiIqKooaNWpQq1YtDAYDU6ZMYciQIURF\nRRnHOby9vfHx8WHRokV8/PHH/P7770RGRhIREWEcTL+evb19sdDJyMhIBg4cWOyzhx56iKioKJKS\nkjAYDJw4cYKePXvy6aefEhkZiYgYGzAo6J2cOHECHx8fevXqxQcffECLFi3Iycnh6tWrlf7306pW\nq1at+PLLL3FycuL8+fOMHTuWMWPG4OrqyhNPPFFsLZGIiAjGjx+PwWDgbk4Key/Q8zwq2Ycffsj3\n33/Pww8/jJ2dnTF/0/Wzr7Ozs3n99dfJysoiPj6eLVu24OTkRHx8PJmZmSVmn61duzbBwcH06dOH\nkydPcvLkSbp06UKDBg2IiYnhjz/+IDQ0lCtXrtCiRQsiIiKwtLQ01m3evHkkJSXx2WefAQXjDnv2\n7OHTTz8tdg8ZGRlER0ezcOFCjh8/Tp06dfDy8iIpKem2/jbt2rXj2LFjbN++/bbPVSg8PJzff/+d\nmJiYMtd0qFmzJvHx8fzrX/8iKCiIhIQEHnroIVq0aMHEiROpX79+pdRHq1r29vYlhltPnz6d6dOn\n37Df29u72KPKjz/++I7W735WKT0PpVSgUmq/UuqQUurNEj6vpZRafO3z/1NK2VfGde82CQkJ/PTT\nTyQmJvLrr78SFxcHlBweajAYmDZtGoMHDy4xa2xJs7iLevnll41jFDExMaSlpTF9+nTWrl3L9u3b\n8fHxMa7OVujpp59m5cqVpY47FHr99dc5ffo0SilCQkIqdUW0p59+Gj8/P2xsbCrtnOXRt29fANzc\n3HBxcaFRo0bUqlWL5s2bc+zYsWJlN2zYQJ8+faq0fpp2r7ntnodSyhT4EngcOA7EKaWiRWRPkWLP\nAedF5DGl1BBgBjD4xrPd22JjY+nfvz916tQBCr6wsrOzy5x9XZqSZnGXZevWrezZs8cYdXL16lXa\nt29frIylpSVdu3Zl1apVODk53TDuUHiNBg0acODAAeP+wl9wwcHBBAcH31D++s8iIyON+zds2FCs\nDps2bSoWZVWSDRs2ULNmTTp06AAU9C7q1KnDyJEjyzyuLEUjtq6P5iorgkvTtJJVRs+jLXBIRA6L\nyFXgJ+D6xYKDgMLV7JcB3dT1IRL3qVsND70+++zNvuBEhMcff9x4jT179vDdd9/dUO7555+/6bjD\nnZCeno6joyO1a9emW7duZZbdsGEDmzdvBmD+/Pl89dVXfPLJJzzzzDOkpKTQtWtX3N3d6datG0eP\nHgVgwoQJzJ8/n2XLltG8eXNSUlJYsmQJTk5OxR5rxMXF8eeff+Ll5cWgQYPIy8sD4Pfff6d169Z4\neXmxYsUKoOD/u5YtW5Kammrcfuyxx4zbd4N9+/bRoUMH3Nzc6NSpE2lpadVdpQfC0KFDcXd3v+GR\nb1mioqLYs2fPzQvegvKOfyqlNiilKmWhqMpoPJoARfv9x6/tK7GMiOQCGcB995C5Y8eOREVFkZWV\nxcWLF1m5ciV16tS5Y+GhRbPO+vr68ueff3Lo0CGgYE5G0d5DocJxh0WLFjF06NBKqUd5WFtb4+zs\nzOHDh3FxcWHu3LlAwZe2l5cXHh4edOvWjZSUFMLDw/n0009p3bo177zzDoGBgTzzzDP861//YtSo\nUfz3v/8FMA6OAqxfv559+/aRn59PdnY2ixYtIiAggN27d3Pp0iX2799PWloaCxYsoF27dsZHe8eO\nHePKlSuMGTOGlStXkpCQwN9//w0U9EpGjBhhjMpZu3YtHh4e2NraVtnfrTwWLFjArl276NChA+Hh\n4dVdnfve33//TVxcHElJSTftRRfKzc29KxqPynTXRVsppV5QSsUrpeLvpl945eHl5cXgwYPx8PCg\nZ8+exiiPOxUe+sILLxAYGEiXLl2wtbUlMjLS+Iuoffv2peZtqq5xh3nz5pGQkEB8fDyzZ8/m9OnT\njBkzxpgKZenSpdjb2xMSEsLEiRMZP348I0eOND4GfOihh/jzzz+ZO3cuSUlJ9OzZk/Xr15OSkoKJ\niQkGg4EzZ87wwQcfUKNGDT755BNMTEzo378/FhYWbN26lRMnTvD3339jMBj4/vvv6datGxYWFjg4\nONCyZUuUUowYMcJY59GjRxsz8s6bN69Ke2vl0bp1a5o3bw4UPA41Nzev5hrde65f4CwsLIypU6fS\nuXNn3njjDdq2bYujo6MxK3SPHj04ceIEBoOB2NhYEhMT8fX1xd3d3ZjzDQpC5F999VV8fHyYMWMG\n0dHRTJ48GYPBQHJycrEQ+rS0NOzt7YGCx75PPfUUgYGBtGzZktdff91Yt7Fjx+Lj44OLiwuhoaFA\nQVqhwuCZLl26AKCU6qGU2qKU2q6UWqqU+l/kTMHno5VSnxXZHqOUKn83Cgp+Cd/OC2gP/LvI9lvA\nW9eV+TfQ/tr7GkAa19ZPL+vl7e0tWuXr3bu3rF27tsqvGxoaKu7u7uLu7i716tWTadOmybBhw0os\nN3PmTJk9e7a8/fbbxu309HQxMTGRq1eviojI3r17xdTUVEREGjZsKB988IGIiGzbtk3MzMyM5xs1\napQsXbpUoqOjZciQITdcb8eOHRIQEGDc/uWXX6R3797G7cDAQFm3bp04ODhIbm5u5fwxKtnvv/8u\nrVu3lvPnz1d3Ve45R44cERcXF+P2zJkzJTQ0VDp16iSTJk0SEZHVq1dLt27dSizv5uYmGzZsEBGR\n9957T1555RUREenUqZOMHTvWWK7w32GhTp06SVxcnIiIpKamSrNmzUREJCIiQhwcHCQ9PV2ysrKk\nadOmcvToUREROXv2rIiI5ObmSqdOnWTnzp0iItKsWTNJTU0VEREgEdgIWBRs8gYw5dr7DYAPYAkk\nA2bX9m8G3KQC3/2V0fOIA1oqpRyUUjWBIUD0dWWigVHX3g8E1l+7Sa2SFYbmnjx50jg/IjIykgkT\nJlRo3KEoe3v7236WvmHDBtauXcuWLVvYuXMnnp6exeZilKRr164sXbrU2B0/f/48NWvW5KeffgIg\nOjq6WCiymZkZUDBGVJLSHu21bt2alJQUkpOTAfjxxx+LHff8888zYsQIY2r5u01+fj7PPfcc0dHR\nN50npFVMYYqb0oJWMjIyylxG+fr8auXVrVs3rKysMDc3x9nZ2fiodsmSJXh5eeHp6cnu3btLewxm\nATgDfyqlEin47m1WtICIZALrgT5KqdYUNCK7KlLH2248pGAMYwIFvYu9wBIR2a2UmqaU6nut2HdA\nfaXUIWAScEM4772svOt6F50dXrTLWvTLuTDC6FZERkaSn58PQOPGjY0zawtZW1tz4MAB4/hLVcrI\nyMDGxoY6deqwb98+tm7dSnZ2Nhs3buTIkSMAxhxahWM5Li4uvPPOO0RGRjJr1iymTp2Kvb09n376\nKe7u7oSHh1dovY/SHu2Zm5szd+5cevfujZeXFw8//HCx4/r27UtmZuZd98iq0MmTJ7GysqJly5bV\nXZV7Uo0aNYz/3QDFUpkUBq6UJ2ilJBYWFuW67vXpU0oKmDly5AhhYWGsW7eOpKQkevfuXVbalTUi\nYrj2chaR50oo8y0QDDwLRJTweZkqZZKgiPwK/HrdvilF3mcDg64/7kGSl5fHtGnTblquMMroVhTO\nrobSF7pZvXo106dPZ+XKlYgIISEhxoilzz77DD8/P86ePcvQoUM5ceIE7du3r5SZuIGBgYSHh+Pk\n5ESrVq3w9fXF1taWuXPn8tRTT5Gfn8/DDz/MmjVrePLJJxk4cCC//PILn3/+OePGjcPS0pLXXnuN\nxMREQkJCyM3Nxd3d3Zj+pTABI0DTpk2L5ckqGjrctWtX4/yb6+tX2hjRzp078fDwMCZ7vNvY2Njw\nySefVHc17lkNGzbkzJkznD17FktLS1atWkVgYGC5ji1rGeXrXb+ssr29PQkJCbRt2/aGH3oluXDh\nAhYWFlhZWXH69Gl+++03OnfuXOzcDRo0ALgE+CmlHhORQ0opC6CJiBSLoBGR/1NK2QFegHu5brgI\nPcO8khSuKbB9+3ZcXFyYP38+zs7ODB48mDVr1vD666/z+++/06dPH+PjpJJYWlqSmZlJZmYmQUFB\nnD9/npycHKZPn05QUBApKSklzj5fvXo18fHxXLlyBYPBYHy0U9TPP//MrFmz+PXXX7GxsWHYsGFM\nnDgRf39/jh49yhNPPMHevXt5//338ff3Z8qUKaxevbrEkN+KqlWrFr/99luJn/Xs2bPYtqOjY7EZ\n6AEBAcb3BoOhxFUHi84nadCgwU3nxZTXRx99xJw5c+7qPEgZGRl8++235f7C04ozMzNjypQptG3b\nliZNmlT4R8L3339PSEgIly9fpnnz5jck5Cw0ZMgQxowZw+zZs1m2bBmvvfYaTz/9tLHXezMeHh54\nenrSunXrYpmE4X/BM9d+NOVS0KP4USlV2IV5F7gx/BKWAAYROV+RewZuf8D8Tr7ulQHzI0eOCCCb\nNm0SEZFnn31WZs6cKc2aNZMZM2YYyxUdMCs6WFZ0sMvCwkJERHJyciQjI0NECgbTWrRoIfn5+XLk\nyBExNTWVHTt2iIjIoEGD5IcffjCe09zc3FinwkG9iIgIcXJyknbt2hnPKSJia2srHh4exlfjxo3l\n4sWL4uHhIcnJycZyNjY2xvppmnZ3A+Kl/AFPq4Bu5S1f9HXXhereq0paUwBufcBMRHj77bdxd3en\ne/funDhxgtOnTwMVm32ekpLCu+++S4sWLbh48aJx7seUKVPIzs5m69atWFtb8+2333LixIliA9Bl\nKTp+o2navUUpZa2UOgBkici6WzmHbjwqSUlrCkDZA2ZlWbhwIampqSQkJJCYmEjDhg2Ng2MVnX0O\n0KxZM5YvX87IkSPZvXs306ZNo0+fPnz++efGMomJiUDBZMdFixYB8Ntvvxnj1gsVjt8UZvetaqUF\nKOgGTdPKR0TSRcRRRG55LFo3HpWktDUFblVGRgYPP/wwZmZmxMTEGEP1ylK3bt0S9+fn5xMTE8OA\nAQOwsrJiwIABDBgwgO7duxMfH098fDyDBg0iPDycsWPHsnHjRj766CNsbW1ZsWIFTZs2xcvLizfe\neAMvLy+WLl1KcHCwcZBv3bp1eHp64ubmZkzlDsWjyOLj442De//5z38wGAwYDAY8PT2LDSLejpIa\ntPDwcOMkvzuhvJF2mna/0Y1HJSlpTYHbMXz4cOLj43Fzc2P+/PnlGsQLDg6madOmGAwGGjZsaIy0\nOnPmDAsXLmT37t3Y2dnx7rvvUrduXerVq8fixYvx8fFh6dKlhIeH8+GHH5KYmEhGRgYuLi689NJL\n/Pe//8XExIT69euzfft2hgwZYrxmdnY2wcHBLF68mF27dpGbm8ucOXPKrGdYWBhffvkliYmJxMbG\n3pBRuDzy8vIYM2YMLi4u9OjRg6ysrGINmr29PW+99Rbh4eHMnj2b7du388QTT9CiRQudwkPTKoGO\ntqoEpa0pcP1YRGnZZouWy8zMBAoihgp7MtcrGn772muvGd8X9iiuV5ExkiVLljB37lxyc3M5deoU\ne/bswd29IIqvpPGb/fv34+DggKOjI1AwSerLL7/k1VdfLfUafn5+TJo0ieHDh/PUU0/x6KOPllq2\nJD///LMxj1Xnzp05d+4cNjY2ODo6EhMTQ1hYGHl5eTRt2pR+/fqxfv16evbsycCBA0lLS+Oll17i\n3//+N/PmzePcuXMMGjSI7du3AwWp8AcPHsz27dtJSEhg0qRJZGZm0qBBAyIjI2nUqBEJCQnGVPY9\nevSoUN017X6hex4PgPKOkdxsElJFx29KmwT15ptv8u2335KVlYWfn1+p8ytKsnfvXlatWsVjjz3G\n/v37MTU1xcTEhCtXrmBra8snn3xCx44dyczMNK7h8cgjj9CkSRNWrFjBrFmzaNSoES1btiQ0NJQW\nLVpgZWVlHO8pzDack5PDSy+9xLJly4yNxTvvvAPAs88+y+eff37TBJc3W4ZY0+5luuehGZU1Cak0\nrVq1YteuXbRo0QJfX1/MzMyMk6QKJ0H17Nmz2GJWycnJuLm54ebmRlxcHPv27St3bP26devYtWsX\nFy9exGAwkJWVRbNmzTAxMcHOzg4o6F3NmTOHL7/8kq+//hoTExOsrKzIysoiNDSU9PR0Vq5cyYUL\nF3j88cc5duwYjz/+OO7u7hw6dIjt27fzyiuvEBcXh4ODA1evXuWRRx7BxMQEZ2dnjhw5Ylwr5dKl\nSyQnJ+Pq6kqHDh34+uuvbwie0LT7ke55aEZFJyENGzas2CSk0pibm2NpaUnt2rVJSkrCxMSEkJAQ\nAEJDQ3nllVfw8fEplhPqs88+w9XVFXd3d8zMzG6YJFgWEWHAgAG0aNGCxMRE9u/fT48ePYqdv7B3\nFRUVRUhICAEBAcXW4BAR5s+fT8OGDfH392fXrl3Y2Njg5OSEubk59evXR0SoXbs258+fJy4ujrS0\nNObMmcPmzZtRSrF69WqgYF2HFi1a8Ndff5GVlVXmUriadj/RPY/7RGJiIidPnqRXr17F9tvb25c6\nRlKo6PhL0XGZokobvwkJCeH06dNYW1tz9OhRRo0aZXxMNnbsWP744w8A46x4FxcXmjRpQlxc3C0N\nlHfr1o1PPvnEmHr83LlzN4QSQ0GEWa9evTAzM8PMzAwHBwfOnDlDRkYGFhYWLF26lE6dOnH8+HH+\n8Y9/cPbsWcLDw41jQw0aNMDMzIz4+HjatWtHXl4ednZ2WFtbU7duXdavX0+/fv345JNPOHz4MG5u\nbpw7dw4XFxeefPLJCt+Xpt1rdM/jLnQrCdgK102vauHh4ca11MtaGOdma7KXl7OzMzNmzMDc3Bx3\nd3cef/xxnnzySWrWrElkZKQx9YuHh4dxHZC2bdvStWtXhgwZQnJyMpaWlhw4cIApU6bw0ksvMWHC\nBFavXo2NjY1xXMfU1JRRo0bxxhtv4OnpSU5OjjGAISgoiGXLluHu7s6aNWuws7Nj165djBkzpqxE\ndZp2X9E9j2rwwQcfsGDBAmxtbbGzs8Pb25tVq1ZhMBjYtGkTQ4cOZeTIkSUmLdy2bRuvvPIK2dnZ\n1K5dm4iICBwcHJgyZQpZWVls2rSJt95665Zntt8pFV2TvSyDBw++4f4Ko9QABg4cSPPmzQkODsbP\nz4+HH36YlStX8uKLL+Ll5UVYWBg+PgUrcWZkZNCkSRNiYmJo3LhxsfGKxo0bG9NrW1paMmbMGOP+\nSZMm8fzzz9OqVSsSExPJzMxk2bJlxfKWTZ069ZbvUdPudrrxqGJxcXHGlfNycnLw8vLC29sbgKtX\nrxrTtJeWtLB169bExsZSo0YN1q5dy9tvv83y5cuZNm0a8fHxfPHFF9V2b+VJbQ0Fv+qzsrLuaF28\nvLyoX78+ERERGAwG46qO15s6dSodO3Y0rolxfRbislhbWzNmzBhcXV155JFHSr2Gpt2PdONRxf78\n80+CgoIwNzfH3Ny82PPxor+m165dW2yhlwsXLpCZmUlGRgajRo3i4MGDKKXIycmp0vqXxd7e3jhg\nvH37duM6HdUlJibmhn3Xj/kEBQVx6dKlG8pd32so2rMp+tn06dOZPn16idcPDw+nTp06jBw5sgK1\n1rR7g248qkBhmvWbKTqPIj8/n61bt96wJvWECRPo0qULP//8MykpKXTu3Jng4GAsLCyqPUR0wIAB\nzJ8/HxcXF9q1a2ecOPigKow607T7kR4wr2J+fn6sXLmS7OxsMjMzSw3t7NGjhzFpYXp6Om+//Tbw\nv2f0UDwyqnbt2sVyRBVN1XGnpaSk0KBBA2rXrs0ff/zB7t27mTdvHnv37sXe3r7EiK/qHA+Iiooq\nbfnOMm3YsKFci3VFR0fz0UcflVmm6DLBmnYvuq3GQyn1kFJqjVLq4LX/tSmlXJ5SKvHa6/r1zR8Y\nIsKSJUs4fvw4VlZW+Pj44ObmxuLFizl79qyxXHBwMN27d2fbtm3Y2trSsGFDPv74Y77++mtef/11\n3nzzTWxtbfn88885fdNHzDAAACAASURBVPo0Z86cwdXVlT179mAwGFi8eHE13uXdr7TG4/nnny+1\nUcnNzS1349G3b99SH2UVKmmZYE27l9xuz+NNYJ2ItATWUfra5Fnyv/V0+5ZS5r63YsUKEhMTOXjw\nIEePHuXSpUscOnSIwYMH4+XlhY+PD1evXmXdunUMHTqUxx9/nFdeeYX+/ftjZmbGxIkTiYiIwNnZ\nmaysLBo3bsysWbPYvHkzFhYWtGvXjqysLL755hvOnDljvO60adNo06YNrq6uvPDCC4gIycnJeHl5\nGcscPHiw2Pa9ZsGCBbRt2xaDwcCLL75IXl4elpaWvPPOO3h4eODr68vp06fZvHkz0dHRTJ48GYPB\nQHJyMsnJyQQGBrJjxw5efPFFY7qU4OBgQkJC/n97dx5XVZ0+cPzzFcEFlyJSU3NNEUR2QSGEXCnN\nXadcRh1zyahmftOYv0qlbEzNX4tNZjmmljZDWS6ZjoVLKmkChfuupKkpLqEsFsrz++NezoACekUW\n9Xm/XvfFufee5TnH633uOef7fb6EhITQv39/Zs2axZtvvomfnx8bNmzgyy+/JCQkBH9/fzp27GiN\ntzJv3jyrsvDQoUN55plnCA0NpUmTJlbCyFuNd968efTu3ZuoqCiaNWvG2LFjrf2aM2cOzZs3Jzg4\nmBEjRhAdHV2ah1WpQhU3efQA5tun5wM9i7m+21puM9wnn3ySLl26cP78eXx9fYmOjmbt2rX89ttv\nrFy5knbt2lmXgD766CNrSNbatWtTu3ZtfvzxR9566y3i4uJ47bXXCA0NZcuWLezdu5ddu3bx0Ucf\n5fuFHB0dTUJCQr5e0IXVdLoV7d69m9jYWOLj40lOTsbJyYmFCxeSkZFBmzZt2Lp1K+3atWP27NmE\nhobSvXt3Jk2aRL169ejduze+vr5ERUVRvXp1hg8fbo2ZnpiYyMKFC6lWrRrjxo2jcuXKXLx4kVde\neYXw8HCOHDlCnTp1qFmzJtu3b6dXr14Fxrdu3Tqys7NxdnZm5MiRBc6TnJxsVSaOjY3l6NGjHD9+\nnEmTJrF582bi4+MdqgGmVEkrbvKoLSIn7NO/ALULma+yMSbRGLPZGFNkgjHGjLTPm5i3pMTt5JNP\nPiE5OZnu3bvTt29fKleuTGRkJKtWrSI2NtZqdSUivPPOO6xYsYKmTZty+PBh0tPT8fDwoEKFCtSu\nXZuIiAjOnTvHrl27ePzxx3FycqJu3bq0b9/e2t7atWsJCQmhVatWrFmzhp07dwK2yzRz587l8uXL\nxMbGMmDAgDI5HsW1evVqkpKSaN26NX5+fqxevZpDhw7h4uJCt27dgKv7liQnJ1O3bl3i4+O5fPky\nc+bMITExkcmTJ3PixAkyMjKoU6cO//jHP6hRowYvvfQSgwcPZsiQIUyYMAGAc+fO8Z///IeTJ09S\no0YNtm/fbjW1znXs2DHc3d3ZsmULu3fv5vz581bfkbw6dOhAzZo1qVy5Ml5eXvz0009s2bKFiIgI\n3NzccHZ2pl+/Gx63R6mb7prJwxgTZ4zZUcCjR9757GPnSiGraSgiQcAA4C1jTNPCticiH4hIkIgE\n3XvvvY7sS7kXHh5ObGwsly9fJjU1lfXr1xMcHAzYmunOnTuXDRs2EBUVBUCXLl147733rOa4+/bt\nIzs7m+bNm1vrycrKYvv27YVu8+LFi4wZM4ZFixZd1Qu6T58+rFy5kuXLlxMYGMg999xTwkfgajNm\nzMDT05OBAwc6vOzkyZMBW5IdMmQIycnJVr2rmJgYnJ2drRZoV1YTPnHiBCtXruSll16iatWqhISE\n4OnpySeffMLu3btxcXGhXr16uLq60qpVKyIiInBycqJOnTpWElqwYAGhoaHs3r2b2bNn4+bmZg0/\nnOv48ePs2LEDf39/AgICyMnJYf/+/Vfty42MDqlUWbpm8hCRjiLiXcBjKXDSGHMfgP3vqULWccz+\n9xCwDvC/aXtwC+nVqxc+Pj74+vrSvn17pk2bRp06dQBb66pvv/2Wjh074uLiAtjODLy8vOjevTv7\n9u1j1KhRhISEcODAAZo2bUrz5s356quvCAkJwcvLy0ooJ06csPo45CYKd3d3qxd0rsqVK9OlSxee\nfPLJMrtkNXPmTL755hsWLlzo8LK5yaNDhw4sWrTIus9z9uzZIkderF69OklJScyfP5+goCCys7O5\ncOECrq6uiAhbt27Nl3gqVKhApUqVqF69OhkZGdYXe2ZmptW8ev5829XbgppL9+rVy0psVatWZfjw\n4de1f61bt+bbb7/l3LlzXLp06YZLuihVEorbz2MZMASYYv+79MoZ7C2wMkXkN2OMOxAGTCvmdm8p\nuX08jDHEx8cX2IvZ2dmZs2fP5nutQoUKTJ48mcmTJzNgwAC2bdvGtm3b8PHxYeXKlVStWpV58+bx\nhz/8ARHh6aefxsvLiwYNGlglw6/VC3rgwIEsXry4TAY1Gj16NIcOHeLhhx9m0KBBLFmyJF/ZFQ8P\nD+bNm8eyZcvIzMzk4MGD9OrVi2nTpjFu3DiysrLw8/OjZcuWvPrqqzRr1ozff/8dgGeffRawjTg4\nfPhw1qxZw4ULF3jzzTepXbs2+/bt45FHHqFp06ZMmTKFP//5zzg5OdG/f38efPBBsrKyWLZsGUlJ\nSdYAW48++ih9+/YlKyuLDRs20LNnT2bOnImvry8PPfQQZ86cISwsLN+/b926dVmzZg3p6elUq1aN\nnJycfI0ZilKvXj1eeOEFgoODcXNzo0WLFtSsWfMm/ysodYNE5IYfwD3YWlntB+IAN/vrQcA/7dOh\nwHZgq/3v8Otdf2BgoKiS9frrr8tLL71UZttv2LChpKamSlpammRnZ4uIyDfffCO9e/cWEZG5c+dK\n48aN5ddff5WsrCxp0KCBHDlyREREXF1d863rzJkzIiKSmZkpLVu2lNOnT0tiYqJ07NjRmufcuXMi\nItKqVStp2rSp+Pr6SlBQkAQEBEhAQIB8/fXXUr9+falSpYq1zokTJ8rrr79urSN3u3PnzpUePXpI\nZGSkPPDAAxITE3PVPCIib731lnh7e4u3t7e0adNGDhw4cN3H58KFCyIikp2dLd26dZMvvvjiupdV\ndyYgUYrxvX69jxLfQHEepZk8evToIQEBAeLl5SXvv/++iNi+AJ577jnx8vKSDh06yPfffy8RERHS\nuHFjWbp0qYiIHD58WB588EHx9/cXf39/iY+PFxGR8ePHi6+vr/j6+krdunVl6NCh1jpFRNauXSsR\nERHSp08f8fDwkAEDBkhOTo6IiHz11Vfi4eEhAQEB8vTTT0vXrl1LZJ979uwprVq1ktTU1BJZ//XI\nTR5HjhyRnj17SsuWLcXb21s8PDxExPYF/cQTT1jzR0VFyYYNG0Tk6uQxceJE8fHxER8fH6lRo4Zs\n2rRJzp49K02aNJHo6GhZuXKlXL58WUREIiIiJCEhwVo29/myZctkwIAB1xX73Llz5amnnirW/l/L\nX//6V/H19RUPDw95+umnrc+IUoXR5FHKyaOgX62ArFixQkRsX7SdOnWS33//XZKTk8XX11dERDIy\nMiQrK0tERPbt2ydXxnzu3Dnx9vaWxMREEcmfPGrUqCFHjx6Vy5cvS5s2bWTDhg2SlZUl9evXl0OH\nDomIyGOPPVZiyaM8yE0eQ4YMkbfffltEbAm5YcOGInL1F3TXrl1l7dq1IpI/eaxdu1bCwsIkIyND\nRGzJIHe+CxcuyKJFi6RHjx4ybNgw6/1bIXko5ajSSh5a28puxowZLF68GICjR4+yf/9+XFxcrJZP\nrVq1olKlSjg7O9OqVSurxU12djbR0dFW/4J9+/ZZ6xQRBg0axP/8z/9YlXPzCg4Opn79+gD4+fmR\nkpJCtWrVaNKkCY0bNwZsI9V98MEHJbnr5UJhZVeK4uzsbPWfSEtL4+6776Zq1ars2bOHzZs3A3D6\n9GlcXFzo06cPHh4eDBo0CLDdNM9bziVXmzZtGDNmDIcPH6Zx48acPXsWNze3Arc/dOhQhg4d6vjO\nKnUb0OSBrRNXXFwcmzZtomrVqkRGRnLx4sUCW9zkTue2uMm9Abt161ZycnLyFTKMiYmhfv36hbZk\n0uaZ/zV27FiGDBnCq6++SteuXa9rmZEjR+Lj40NAQAAffvghs2bNwtPTEw8PD9q0aQPY+lkMGzbM\nKhX/2muvAf/tPV6lShVrkCeAe++9lw8++IDevXuTk5NDrVq1+Oabb27y3ip169PkAYX+ar3eZevX\nr0+FChWYP38+ly9fBuDLL78kLi6uwLLgRfHw8ODQoUOkpKTQqFGj275OVe4ZnLu7e76zttzaUFf+\nus9bSHLq1KlMnTrVer5y5coCt/HDDz9c9VqfPn2sVlSQfyjehx9+2KFx1ZW6E2lVXSAqKopLly7h\n6enJuHHjrF+t12PMmDHMnz8fX19f9uzZY7X7f+ONNzh27JhVbym3V/K1VKlShZkzZxIVFUVgYCDV\nq1fX5plKqXLH2O6vlE9BQUFyZbmHO0FunwAR4amnnqJZs2ZFjg+ulFK5jDFJYqvoUaL0zKMcmj17\nttX5LS0tjVGjRpV1SEoplY+eeSil1G1EzzxUiShOIcLrkZiYyDPPPANc/8h7Sqlbj7a2usPMnDmT\nuLg4q3/JzXTp0iWCgoIICrL96Fm3bh3VqlUjNDT0pm9LKVW29MzjDpK3EOHUqVNp27Yt/v7+hIaG\nsnfvXsDWSS53vA+AyMhIEhMTOXv2LD179sTHx4c2bdpYA1TFxMQwePBgwsLCGDx4MOvWraNbt26k\npKRcNfJeamoqffr0oXXr1rRu3Zr4+PgyOQ5KqZugNLqx3+hDCyPefNcqRPjGG2/IhAkTRETk+PHj\n0rx5cxERiY6Otgr/rV692irPMnHiRAkICJDMzEwRsZUJyS2ncmVBwccff9yqS7Vx40ZxcXEp1r6s\nXbvWqiWmlLKhlMqT6JnHHSotLY1+/frh7e3NX/7yF+tso3///taYH59++il9+/YFbEPoDh48GID2\n7dtz5swZzp8/D0D37t2pUqXKNbcZFxdHdHQ0fn5+jBgxgpycHNLT0/ON5+2I672nkpKSwieffGI9\nz3tf5rfffqNjx474+fkV2SFz3rx5On64Unlo8rhDjR8/noceeogdO3bw5ZdfWoNG1atXj3vuuYdt\n27blGxK3KLkdI68lJyeHzZs3k5ycbA2tO2rUKDp06MDRo0fJzMwkKSmJiIgIAgMD6dKlCydO2EY5\nnjFjBl5eXvj4+PDYY48VeFmsMFcmj6CgIGbMmAHAjz/+CNiGpb2efVVK2WjyuEMVVYjwD3/4A9Om\nTSMtLQ0fHx/ANoRu7mh/69atw93dnRo1ahS5jSuLD3bu3Jl33nnHer53717GjBnD6tWrMcYQFhZG\neHg4NWrUYMOGDURGRuLv709gYCB/+9vfWLFiBdu2baNt27bWeN5ubm589913hIeHM3To0HwjJVar\nVg2AcePGsWHDBvz8/HjzzTet+zKnTp1i0KBBJCQk4Ofnx8GDB2nUqBGnT58GbGcokZGRN3B0lbr9\nafK4Q40dO5b//d//xd/f/6qCjH379uXf//43/fv3t16LiYkhKSkJHx8fxo0bZw27WpRHH32UxYsX\nW2cGM2bMIDExER8fHzp16oSrqythYWGALZk5OTlRsWJF4uPjeeCBB5g0aRItWrQgKSmJFi1aEBkZ\nyYIFC+jZsycJCQmMHj2a2rVrM2fOnCLjmDJlCuHh4SQnJ+frqV+rVi3++c9/Wu81bdrUkUOo1B2t\nWE11jTH9gBjAEwgWkQJ79BljooC3ASdsIwxOKc521Y27ViFCgNq1a1+VUNzc3FiyZMlV64uJicn3\nPDIy0vq13rx5c6tVVq7c+wopKSlERERYr9eqVYv7778fZ2dn/v73vzN58mS2bNnCr7/+ip+fHzk5\nObi7u/PDDz/w4osvcv/997N//36ys7N54IEHHD4OSqniKW4/jx1Ab+D9wmYwxjgB7wKdgJ+BBGPM\nMhHZVcxtq1vckSNH2LRpE/fddx8ZGRm0adOG2bNns3PnTqpXr46Xlxdz5szB09OTI0eO0KhRI7Kz\ns5kxYwYLFixgy5YtrF+/3rpfU7FiRav0ek5OjjWeuSPyriN3vUqpqxUreYjIbsAa86IQwcABETlk\nn/ffQA9Ak8cdzsPDg3fffZdNmzaRkZFBcHAwXbp0ISoqCmMMZ86c4eOPP2bSpEkMGDCA1NRUKlWq\nRKVKlfDw8MDNzY2YmBicnZ3ZsGEDjRo1Iikpif79+7Ns2TKys7OBwgd+KkjuOh5++GE+//zzktx9\npW5ppdHDvB5wNM/zn4GQwmY2xowERgI0aNCgZCNTZaZRo0bs2bMHsF3CioqKYs6cOSQlJREWFsbH\nH3/Mvn37eOaZZwgKCuLSpUuMHTuWESNG8N577xESEsK9997L0KFDuXDhAuHh4TRv3pwePXrg6+tL\nVFSU1QrMx8cHJycnfH19GTp0KP7+/oXGNXHiRIYPH8748eP1ZrlSRbhmYURjTBxQp4C3XhSRpfZ5\n1gHPFXTPwxjTF4gSkSfszwcDISJyzUbzWhhRKaUcU1qFEa955iEiHYu5jWPA/Xme17e/ppRS6hZV\nGk11E4BmxpjGxhgX4DFgWSlsVymlVAkpVvIwxvQyxvwMtAW+Msassr9e1xizAkBELgHRwCpgN/Cp\niOwsbJ1KKaXKv+K2tloMLC7g9ePAI3merwBWFGdbSimlyg/tYa5uSYUVU5wwYQJxcXFFLhsTE8P0\n6dMLfC+3pIlSqmg6GJS6rbzyyitlHYJSdwQ981C3rMuXLzNixAhatmxJ586dycrKylccccWKFbRo\n0YLAwECeeeYZunXrZi37xRdf0KJFC5o0aWJV2M3rj3/8Y75yLAMHDmTp0qVFxpM7cNaVtJy7uh1p\n8lC3rP379/PUU0+xc+dO7rrrrnw9wi9evMioUaNYuXIlSUlJpKamXrX81q1b2bJlCy+//LLVGz3X\n8OHDrWrDaWlpfPfdd3Tt2rVE90epW4kmD3XLaty4MX5+fgAEBgayZMkSli9fznPPPcegQYNo3Lgx\nrVq14sUXX2Tz5s3Ex8dz8uRJACpXrsw777xjlZYPCQnBx8eHixcvcu7cOerXr8+qVatITU3lX//6\nF+3btyc4OBiwXRpr3bo13t7ejBw5krwdbT/++GP8/Pzw9vZmy5YtV8WsQ/Gq24UmD3XLqlSpkjV9\n+vRptm/fziOPPML06dOpUKECp06dsgouvv3227i5uTF79mzAVgAx14kTJxg7dizbtm2jQoUKvPzy\nyzRt2pS6desydepU5s6di5OTE8OGDQMgOjqahIQEduzYQVZWFsuXL7fWlZmZSXJyMjNnzuRPf/rT\nVTE/++yz/OUvfyEhIYHPP/+cJ554oqQOj1IlSm+Yq9vCgQMHOH78OMuXL2f9+vW4uLjwyy+/4OLi\nQrdu3Rg0aBA1a9YkJSWF+vXrW8ulpaWRk5NDmzZtAFtSWb9+PQB//etfef755/H09GT16tW89tpr\nAKxdu5Zp06aRmZnJ2bNnadmyJY8++igAjz/+OADt2rXj/Pnz/Prrr/nijIuLY9eu/9YEPX/+POnp\n6drKS91y9MxDlbrU1FRCQkLw9/cvcvjYguQOYXslEcHX15fu3bszffp09u3bx8KFC8nOziYoKIjq\n1avj6up61TglRfnTn/5ETk4OgYGBBAYGcs8993Dx4kXGjBnDokWL2L59OyNGjMhXuv3KCtNXPs87\nFG9ycjLHjh3TxKFuSZo8VKm6dOkSq1evplWrVvz444+Eh4c7tHxu8mjUqBE7duywXp88eTInT55k\n2rRp9O3bl7Nnz9K0aVOqVq1KYmIiFSpUsEYKjImJITQ0FICaNWvi6enJ0aO2ws9jx461BqnKycmh\nYsWKLFmyxLpklZso3N3dSU9PzzfsLfx3sKuNGzdSs2ZNatasme/9K4fiTU5Odmj/lSovNHkoh6Wk\npNCiRQsGDhyIp6cnffv2JTMzk6SkJCIiIggMDMTb29v6wm3UqBHh4eEEBQXx9ttvM3bsWJYuXYqf\nnx9ZWVl8/fXXtG3bloCAAPr160d6ejoACQkJBAYG0rBhQ4KDg0lLS2PChAnExsbi5+dnfVEDeHl5\n8eqrr9K5c2drmNv333+frKwsWrZsSVpaGp06dcq3H7lnBfPnz+dvf/sbPj4+JCcnWx0NPT09GTZs\nGE5OTnTu3BmAu+66ixEjRuDt7U2XLl1o3bp1vnVWrlwZf39/Ro8eXeDwuHmH4vXy8mLWrFk37x9G\nqdIkIuX2ERgYKKr8OXz4sACyceNGEREZNmyYTJs2Tdq2bSunTp0SEZHRo0dLixYtRESkYcOG0rZt\nW2v5uXPnylNPPSUiIqmpqRIeHi7p6ekiIjJlyhR5+eWX5bfffpPGjRvLe++9J127dpW0tDTJzs7O\nt2xxREdHy4cffnjN+V5//XV56aWXir09pUoLkCil8P2sN8zvcAsWLGDGjBn8/vvvhISE8MILL9Cx\nY0c2bdqEm5sbERERjB8/ns6dO/PRRx8xffp0srOzqVq1KmFhYaSmprJ//34WLVpERkYGoaGhuLq6\ncvr0aSpU+O+Jra+vLwAHDx7k//7v/zh58iRbt25lwIAB7Nq1i/vvvx8nJycyMjJwcnLC1dWV++67\nj3nz5rF7927atWvHkCFDuPvuu4u9z+PHj+f777+/avz1K/Xq1YuDBw+yZs2aYm9TqduNJo872O7d\nu4mNjSU+Ph5nZ2fGjBnDt99+y/PPP8+TTz5JcHAwXl5edO7cmZ07d/Lqq6/y3XffkZ6ebt2rePbZ\nZ+nbty/u7u789NNPZGVlkZyczLx58/L1tnZxcQFg5MiRDBo0iKNHjzJ48GBGjBhBp06dqFSpEhkZ\nGcTGxrJnzx66dOlCgwYNmDJlCtOnT7eaw+Z23CuOSZMmMWnSpGvOt3jxVTU/lVJ2mjzuYKtXryYp\nKcm6bp+VlUWtWrWIiYnhs88+Y9asWdYN3TVr1tCvXz/rRvHPP//Mpk2biIuLY9WqVVSqVIkzZ85Q\no0YN0tPTuXTpEmfOnMm3vfT0dL777jv2799PZmYmGzduJCsri/j4eIKCgujTpw9ZWVlUrFiRc+fO\n4ezsbA1Ve+HCBapUqeLQeORKqZKjN8zvYCLCkCFDrGaje/fuJSYmhszMTH7++WcA6+b1lTw8PHj3\n3Xc5e/Ys4eHhHDhwgO+//x5PT0/CwsKYOHEiv/zyS75lcnJyuOuuu3jllVd47LHHSE5OZv/+/cyb\nN4/169fzwgsv0LZtWythxMbGMmPGDNavX0+nTp24ePEiDz30ELt27brqhrlSqpSVxo2VG33oDfOS\ntXPnTnnggQfk5MmTIiJy5swZSUlJkejoaPn73/8uCxYskK5du4qIyI4dO6RZs2Zy+vRpOXz4sHUz\n/PHHH5dp06ZZ6/zxxx9FJP9N8YkTJ8rrr78uIiJt27aVTz/9VEREcnJyJDk5WUREhgwZIp999pm1\nHldXVxERSUxMlHbt2pXYMVDqdkMp3TAv7kiC/YwxO40xOcaYQgdcN8akGGO2G2OSjTFXlx1VZaKg\n5q0pKSkkJCTw/PPPM3DgQFxcXJg7dy4tW7bkxRdfJCIigocfftg6q3C06enChQuZM2cOvr6+tGzZ\n8pqVan18fHBycsLX15c333zzpu27Uqp4jC1R3eDCxngCOcD7wHMiUmBiMMakAEEictqR9QcFBUlB\nJa6VUkoVzBiTJCKF/pi/WYo7DO1uuLoEg1JKqdtbad0wF+BrY0ySMWZkKW1TKaVUCbnmmYcxJg6o\nU8BbL4pI0Res/+tBETlmjKkFfGOM2SMi6wvZ3khgJECDBg2uc/VKKaVK0zWTh4h0LO5GROSY/e8p\nY8xiIBgoMHmIyAfAB2C751HcbSullLr5SvyylTHG1RhTPXca6AzsKHoppZRS5Vlxm+r2Msb8DLQF\nvjLGrLK/XtcYkzvoQm1gozFmK7AF+EpE/lOc7SqllCpbxW1ttRi4qgCQiBwHHrFPHwJ8i7MdpZRS\n5YuWJ1FKKeUwTR5KKaUcpslDKaWUwzR5KKWUcpgmD6WUUg7T5KGUUsphmjyUUko5TJOHUkoph2ny\nUEop5TBNHkoppRymyUMppZTDNHkopZRymCYPpZRSDtPkoZRSymGaPJRSSjlMk4dSSimHafJQSinl\nME0eSimlHGZEpKxjKJQxJhX4qazjsHMHTpd1EIXQ2G6Mxua48hoXaGy5GorIvSW9kXKdPMoTY0yi\niASVdRwF0dhujMbmuPIaF2hspU0vWymllHKYJg+llFIO0+Rx/T4o6wCKoLHdGI3NceU1LtDYSpXe\n81BKKeUwPfNQSinlME0ehTDG9DPG7DTG5BhjCm0lYYxJMcZsN8YkG2MSy1lsUcaYvcaYA8aYcaUU\nm5sx5htjzH7737sLme+y/ZglG2OWlWA8RR4DY0wlY0ys/f3vjTGNSiqWG4htqDEmNc9xeqIUY/vQ\nGHPKGLOjkPeNMWaGPfZtxpiAchJXpDEmLc8xm1Aacdm3fb8xZq0xZpf9/+ezBcxTJsetRIiIPgp4\nAJ6AB7AOCCpivhTAvbzFBjgBB4EmgAuwFfAqhdimAePs0+OAqYXMl14KsVzzGABjgFn26ceA2FL6\nN7ye2IYC/yjNz1aebbcDAoAdhbz/CLASMEAb4PtyElcksLyMjtl9QIB9ujqwr4B/0zI5biXx0DOP\nQojIbhHZW9ZxFOQ6YwsGDojIIRH5Hfg30KPko6MHMN8+PR/oWQrbLMz1HIO88S4COhhjTDmJrcyI\nyHrgbBGz9AA+EpvNwF3GmPvKQVxlRkROiMgP9ukLwG6g3hWzlclxKwmaPIpPgK+NMUnGmJFlHUwe\n9YCjeZ7/zNUf5JJQW0RO2Kd/AWoXMl9lY0yiMWazMaakEsz1HANrHhG5BKQB95RQPI7GBtDHfnlj\nkTHm/lKI63qV8JCBZAAAAoBJREFU1efrerQ1xmw1xqw0xrQsiwDslz/9ge+veKs8HzeHVCzrAMqS\nMSYOqFPAWy+KyNLrXM2DInLMGFML+MYYs8f+66g8xFYiioot7xMREWNMYc35GtqPWxNgjTFmu4gc\nvNmx3uK+BP4lIr8ZY0ZhO0NqX8YxlXc/YPtspRtjHgGWAM1KMwBjTDXgc+DPInK+NLddmu7o5CEi\nHW/COo7Z/54yxizGdjmi2MnjJsR2DMj7S7W+/bViKyo2Y8xJY8x9InLCfjp+qpB15B63Q8aYddh+\npd3s5HE9xyB3np+NMRWBmsCZmxzHDcUmInnj+Ce2+0nlRYl9vooj75e1iKwwxsw0xriLSKnUlTLG\nOGNLHAtF5IsCZimXx+1G6GWrYjDGuBpjqudOA52BAluBlIEEoJkxprExxgXbzeASa9WUxzJgiH16\nCHDVWZIx5m5jTCX7tDsQBuwqgViu5xjkjbcvsEbsdzZL2DVju+JaeHds19DLi2XAH+2th9oAaXku\nV5YZY0yd3HtWxphgbN9xpfFjAPt25wC7ReSNQmYrl8fthpT1Hfvy+gB6Ybse+RtwElhlf70usMI+\n3QRbK5mtwE5sl5TKRWz2549ga/FxsBRjuwdYDewH4gA3++tBwD/t06HAdvtx2w4ML8F4rjoGwCtA\nd/t0ZeAz4ACwBWhSip+xa8X2mv1ztRVYC7Qoxdj+BZwAsu2fteHAaGC0/X0DvGuPfTtFtEgs5bii\n8xyzzUBoKR6zB7HdA90GJNsfj5SH41YSD+1hrpRSymF62UoppZTDNHkopZRymCYPpZRSDtPkoZRS\nymGaPJRSSjlMk4dSSimHafJQSinlME0eSimlHPb/TMp/0fABl8sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUb3L7pqLS86",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 6：尝试改进模型的效果\n",
        "\n",
        "看看您能否优化该模型以改进其效果。您可以尝试以下几种做法：\n",
        "\n",
        "* **更改超参数**或**使用其他优化工具**，比如 Adam（通过遵循这些策略，您的准确率可能只会提高一两个百分点）。\n",
        "* **向 `informative_terms` 中添加其他术语。**此数据集有一个完整的词汇表文件，其中包含 30716 个术语，您可以在以下位置找到该文件：https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt 您可以从该词汇表文件中挑选出其他术语，也可以通过 `categorical_column_with_vocabulary_file` 特征列使用整个词汇表文件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-b3BqXvLS86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f7caaab2-d552-4222-b09c-8edacf7a4f37"
      },
      "source": [
        "# Download the vocabulary file.\n",
        "terms_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt'\n",
        "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt\n",
            "253952/253538 [==============================] - 0s 0us/step\n",
            "262144/253538 [===============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jbJlwW5LS8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "147bef0c-8ff8-42a6-a997-bda50e0045f3"
      },
      "source": [
        "# Create a feature column from \"terms\", using a full vocabulary file.\n",
        "informative_terms = None\n",
        "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
        "  # Convert it to a set first to remove duplicates.\n",
        "  informative_terms = list(set(f.read().split()))\n",
        "  \n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", \n",
        "                                                                                 vocabulary_list=informative_terms)\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[10,10],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "loss 9.79771\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.81224\n",
            "auc 0.90506387\n",
            "prediction/mean 0.48596781\n",
            "precision 0.84117645\n",
            "label/mean 0.5\n",
            "average_loss 0.3919084\n",
            "auc_precision_recall 0.90378726\n",
            "accuracy 0.82944\n",
            "---\n",
            "Test set metrics:\n",
            "loss 10.368902\n",
            "accuracy_baseline 0.5\n",
            "global_step 1000\n",
            "recall 0.79872\n",
            "auc 0.8933097\n",
            "prediction/mean 0.4867514\n",
            "precision 0.82491946\n",
            "label/mean 0.5\n",
            "average_loss 0.4147561\n",
            "auc_precision_recall 0.8910014\n",
            "accuracy 0.8146\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew3kwGM-LS9B",
        "colab_type": "text"
      },
      "source": [
        " ## 总结\n",
        "\n",
        "我们可能获得了比我们原来的线性模型更好且具有嵌入的 DNN 解决方案，但线性模型也相当不错，而且训练速度快得多。线性模型的训练速度之所以更快，是因为它们没有太多要更新的参数或要反向传播的层。\n",
        "\n",
        "在有些应用中，线性模型的速度可能非常关键，或者从质量的角度来看，线性模型可能完全够用。在其他领域，DNN 提供的额外模型复杂性和能力可能更重要。在定义模型架构时，请记得要充分探讨您的问题，以便知道自己所处的情形。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MquXy9zLS9B",
        "colab_type": "text"
      },
      "source": [
        " ### *可选内容：*在 `embedding_column` 与 `indicator_column` 之间进行权衡\n",
        "\n",
        "从概念上讲，在训练 `LinearClassifier` 或 `DNNClassifier` 时，需要根据实际情况使用稀疏列。TF 提供了两个选项：`embedding_column` 或 `indicator_column`。\n",
        "\n",
        "在训练 LinearClassifier（如**任务 1** 中所示）时，系统在后台使用了 `embedding_column`。正如**任务 2** 中所示，在训练 `DNNClassifier` 时，您必须明确选择 `embedding_column` 或 `indicator_column`。本部分通过一个简单的示例讨论了这两者之间的区别，以及如何在二者之间进行权衡。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_3XuZ_LLS9C",
        "colab_type": "text"
      },
      "source": [
        " 假设我们的稀疏数据包含 `\"great\"`、`\"beautiful\"` 和 `\"excellent\"` 这几个值。由于我们在此处使用的词汇表大小为 $V = 50$，因此第一层中的每个单元（神经元）的权重将为 50。我们用 $s$ 表示稀疏输入中的项数。对于此示例稀疏数据，$s = 3$。对于具有 $V$ 个可能值的输入层，带有 $d$ 个单元的隐藏层需要运行一次“矢量 - 矩阵”乘法运算：$(1 \\times V) * (V \\times d)$。此运算会产生 $O(V * d)$ 的计算成本。请注意，此成本与隐藏层中的权重数成正比，而与 $s$ 无关。\n",
        "\n",
        "如果输入使用 [`indicator_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column) 进行了独热编码（长度为 $V$ 的布尔型矢量，存在用 1 表示，其余则为 0），这表示很多零进行了相乘和相加运算。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7mR4Wa2LS9C",
        "colab_type": "text"
      },
      "source": [
        " 当我们通过使用大小为 $d$ 的 [`embedding_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column) 获得完全相同的结果时，我们将仅查询与示例输入中存在的 3 个特征 `\"great\"`、`\"beautiful\"` 和 `\"excellent\"` 相对应的嵌入并将这三个嵌入相加：$(1 \\times d) + (1 \\times d) + (1 \\times d)$。由于不存在的特征的权重在“矢量-矩阵”乘法中与 0 相乘，因此对结果没有任何影响；而存在的特征的权重在“矢量-矩阵”乘法中与 1 相乘。因此，将通过嵌入查询获得的权重相加会获得与“矢量-矩阵”乘法相同的结果。\n",
        "\n",
        "当使用嵌入时，计算嵌入查询是一个 $O(s * d)$ 计算；从计算方面而言，它比稀疏数据中的 `indicator_column` 的 $O(V * d)$ 更具成本效益，因为 $s$ 远远小于 $V$。（请注意，这些嵌入是临时学习的结果。在任何指定的训练迭代中，都是当前查询的权重。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etZ9qf0kLS9D",
        "colab_type": "text"
      },
      "source": [
        " 正如我们在**任务 3** 中看到的，通过在训练 `DNNClassifier` 过程中使用 `embedding_column`，我们的模型学习了特征的低维度表示法，其中点积定义了一个针对目标任务的相似性指标。在本例中，影评中使用的相似术语（例如 `\"great\"` 和 `\"excellent\"`）在嵌入空间中彼此之间距离较近（即具有较大的点积），而相异的术语（例如 `\"great\"` 和 `\"bad\"`）在嵌入空间中彼此之间距离较远（即具有较小的点积）。"
      ]
    }
  ]
}